{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58592, 41)\n",
      "Training set shape: (16000, 40)\n",
      "Test set shape: (4000, 40)\n",
      "\n",
      "Class distribution in splits:\n",
      "Training set: claim_status\n",
      "0    0.935063\n",
      "1    0.064937\n",
      "Name: proportion, dtype: float64\n",
      "Test set: claim_status\n",
      "0    0.935\n",
      "1    0.065\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('../data/Insurance_claims_data.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "test_df = df.sample(20000, random_state=23)\n",
    "\n",
    "# Create train/test split with stratification since data is imbalanced\n",
    "X = test_df.drop('claim_status', axis=1)\n",
    "y = test_df['claim_status']\n",
    "\n",
    "# Use stratify parameter to maintain class distribution in both splits\n",
    "# Use test_size=0.2 for 80/20 split which is common practice\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42, # For reproducibility\n",
    "    stratify=y # Maintain class distribution\n",
    ")\n",
    "\n",
    "# Print shapes to verify split\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(\"\\nClass distribution in splits:\")\n",
    "print(\"Training set:\", pd.Series(y_train).value_counts(normalize=True))\n",
    "print(\"Test set:\", pd.Series(y_test).value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "from src.modules.fe import CAAFETransformer\n",
    "\n",
    "model = XGBClassifier(\n",
    "        seed=42,\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"logloss\",\n",
    "        n_jobs=-1,\n",
    "        use_label_encoder=False,\n",
    "        verbosity=0,\n",
    "        enable_categorical=True,\n",
    "    )\n",
    "\n",
    "fe = CAAFETransformer(\n",
    "    llm_model='gpt-4.1-mini',\n",
    "    target_name=\"claim_status\",\n",
    "    dataset_description=\"Insurance claim data.\",\n",
    "    max_features=5,\n",
    "    iterations=3,\n",
    "    n_splits=5,\n",
    "    n_repeats=2,\n",
    "    random_state=123,\n",
    "    base_classifier=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-06-02 22:23:41] INFO:src.modules.fe.CAAFETransformer: Starting CAAFETransformer.fit(): running iterative feature engineering.\n",
      "[2025-06-02 22:23:41] INFO:src.modules.fe.CAAFETransformer: CAAFE transformer initialization completed:\n",
      "  Target: claim_status\n",
      "  Dataset shape: (16000, 41)\n",
      "  Original features: 40\n",
      "  Max features per iteration: 5\n",
      "  Max iterations: 3\n",
      "  Optimization metric: accuracy\n",
      "  LLM model: gpt-4.1-mini\n",
      "  CV splits: 5\n",
      "  CV repeats: 2\n",
      "[2025-06-02 22:23:41] INFO:src.modules.fe.CAAFETransformer: Starting iterative feature engineering process...\n",
      "[2025-06-02 22:23:41] INFO:src.modules.fe.CAAFETransformer: \n",
      "\n",
      "→ Evaluating baseline performance (no added features)...\n",
      "\n",
      "[2025-06-02 22:23:49] INFO:src.modules.fe.CAAFETransformer: \n",
      "Baseline ROC AUC: 0.539 (±0.021)\n",
      "[2025-06-02 22:23:49] INFO:src.modules.fe.CAAFETransformer: \n",
      "Baseline Accuracy: 0.934 (±0.005)\n",
      "[2025-06-02 22:23:49] INFO:src.modules.fe.CAAFETransformer: \n",
      "\n",
      "--- Iteration 1/3 ---\n",
      "\n",
      "[2025-06-02 22:24:13] INFO:src.modules.fe.CAAFETransformer: \n",
      "\n",
      "Prompt for iteration 1:\n",
      "---ITERATION 1---\n",
      "\n",
      "\n",
      "Generate new features to improve classification performance.\n",
      "\n",
      "Dataset description:\n",
      "Insurance claim data.\n",
      "\n",
      "Target variable: claim_status\n",
      "\n",
      "Dataset summary:\n",
      "Dataset shape: 16000 rows, 41 columns\n",
      "Target column: claim_status\n",
      "\n",
      "Columns:\n",
      "- policy_id (object): NaN-freq [0.0%], Samples: ['POL045937', 'POL043655', 'POL036713', 'POL044861', 'POL033737'], Importance: 0.000937\n",
      "- subscription_length (float64): NaN-freq [0.0%], Samples: [0.5, 0.9, 1.5, 0.8, 4.3], Importance: -0.000563\n",
      "- vehicle_age (float64): NaN-freq [0.0%], Samples: [0.0, 2.4, 3.2, 2.6, 0.8], Importance: 0.000500\n",
      "- customer_age (int64): NaN-freq [0.0%], Samples: [47, 38, 39, 49, 58], Importance: 0.000687\n",
      "- region_code (object): NaN-freq [0.0%], Samples: ['C7', 'C2', 'C9', 'C9', 'C14'], Importance: 0.000437\n",
      "- region_density (int64): NaN-freq [0.0%], Samples: [6112, 27003, 17804, 17804, 7788], Importance: 0.000500\n",
      "- segment (object): NaN-freq [0.0%], Samples: ['A', 'B2', 'A', 'C2', 'A'], Importance: 0.000563\n",
      "- model (object): NaN-freq [0.0%], Samples: ['M1', 'M6', 'M3', 'M4', 'M1'], Importance: 0.000437\n",
      "- fuel_type (object): NaN-freq [0.0%], Samples: ['CNG', 'Petrol', 'Petrol', 'Diesel', 'CNG'], Importance: 0.000750\n",
      "- max_torque (object): NaN-freq [0.0%], Samples: ['60Nm@3500rpm', '113Nm@4400rpm', '91Nm@4250rpm', '250Nm@2750rpm', '60Nm@3500rpm'], Importance: 0.000437\n",
      "- max_power (object): NaN-freq [0.0%], Samples: ['40.36bhp@6000rpm', '88.50bhp@6000rpm', '67.06bhp@5500rpm', '113.45bhp@4000rpm', '40.36bhp@6000rpm'], Importance: -0.000062\n",
      "- engine_type (object): NaN-freq [0.0%], Samples: ['F8D Petrol Engine', 'K Series Dual jet', '1.0 SCe', '1.5 L U2 CRDi', 'F8D Petrol Engine'], Importance: -0.000375\n",
      "- airbags (int64): NaN-freq [0.0%], Samples: [2, 2, 2, 6, 2], Importance: 0.000000\n",
      "- is_esc (object): NaN-freq [0.0%], Samples: ['No', 'No', 'No', 'Yes', 'No'], Importance: -0.000313\n",
      "- is_adjustable_steering (object): NaN-freq [0.0%], Samples: ['No', 'Yes', 'No', 'Yes', 'No'], Importance: 0.000062\n",
      "- is_tpms (object): NaN-freq [0.0%], Samples: ['No', 'No', 'No', 'Yes', 'No'], Importance: 0.000000\n",
      "- is_parking_sensors (object): NaN-freq [0.0%], Samples: ['Yes', 'Yes', 'No', 'Yes', 'Yes'], Importance: 0.000000\n",
      "- is_parking_camera (object): NaN-freq [0.0%], Samples: ['No', 'No', 'Yes', 'Yes', 'No'], Importance: 0.000625\n",
      "- rear_brakes_type (object): NaN-freq [0.0%], Samples: ['Drum', 'Drum', 'Drum', 'Disc', 'Drum'], Importance: 0.000000\n",
      "- displacement (int64): NaN-freq [0.0%], Samples: [796, 1197, 999, 1493, 796], Importance: 0.000125\n",
      "- cylinder (int64): NaN-freq [0.0%], Samples: [3, 4, 3, 4, 3], Importance: 0.000563\n",
      "- transmission_type (object): NaN-freq [0.0%], Samples: ['Manual', 'Manual', 'Automatic', 'Automatic', 'Manual'], Importance: 0.000000\n",
      "- steering_type (object): NaN-freq [0.0%], Samples: ['Power', 'Electric', 'Electric', 'Power', 'Power'], Importance: 0.000000\n",
      "- turning_radius (float64): NaN-freq [0.0%], Samples: [4.6, 4.8, 5.0, 5.2, 4.6], Importance: 0.000250\n",
      "- length (int64): NaN-freq [0.0%], Samples: [3445, 3845, 3731, 4300, 3445], Importance: 0.000625\n",
      "- width (int64): NaN-freq [0.0%], Samples: [1515, 1735, 1579, 1790, 1515], Importance: -0.000188\n",
      "- gross_weight (int64): NaN-freq [0.0%], Samples: [1185, 1335, 1155, 1720, 1185], Importance: -0.000125\n",
      "- is_front_fog_lights (object): NaN-freq [0.0%], Samples: ['No', 'Yes', 'No', 'Yes', 'No'], Importance: 0.001000\n",
      "- is_rear_window_wiper (object): NaN-freq [0.0%], Samples: ['No', 'No', 'No', 'Yes', 'No'], Importance: 0.000000\n",
      "- is_rear_window_washer (object): NaN-freq [0.0%], Samples: ['No', 'No', 'No', 'Yes', 'No'], Importance: 0.000000\n",
      "- is_rear_window_defogger (object): NaN-freq [0.0%], Samples: ['No', 'No', 'No', 'Yes', 'No'], Importance: -0.000250\n",
      "- is_brake_assist (object): NaN-freq [0.0%], Samples: ['No', 'Yes', 'No', 'Yes', 'No'], Importance: 0.000187\n",
      "- is_power_door_locks (object): NaN-freq [0.0%], Samples: ['No', 'Yes', 'Yes', 'Yes', 'No'], Importance: 0.000000\n",
      "- is_central_locking (object): NaN-freq [0.0%], Samples: ['No', 'Yes', 'Yes', 'Yes', 'No'], Importance: 0.000000\n",
      "- is_power_steering (object): NaN-freq [0.0%], Samples: ['Yes', 'Yes', 'Yes', 'Yes', 'Yes'], Importance: 0.000000\n",
      "- is_driver_seat_height_adjustable (object): NaN-freq [0.0%], Samples: ['No', 'Yes', 'No', 'Yes', 'No'], Importance: 0.000375\n",
      "- is_day_night_rear_view_mirror (object): NaN-freq [0.0%], Samples: ['No', 'Yes', 'Yes', 'No', 'No'], Importance: 0.000812\n",
      "- is_ecw (object): NaN-freq [0.0%], Samples: ['No', 'Yes', 'Yes', 'Yes', 'No'], Importance: 0.000000\n",
      "- is_speed_alert (object): NaN-freq [0.0%], Samples: ['Yes', 'Yes', 'Yes', 'Yes', 'Yes'], Importance: 0.000000\n",
      "- ncap_rating (int64): NaN-freq [0.0%], Samples: [0, 2, 2, 3, 0], Importance: 0.000875\n",
      "- claim_status (int64): NaN-freq [0.0%], Samples: [0, 0, 0, 0, 0]\n",
      "\n",
      "Target distribution: {0: 0.9350625, 1: 0.0649375}\n",
      "\n",
      "Generate up to 5 meaningful features that:\n",
      "1. Add semantic information based on real-world knowledge and df characteristics\n",
      "2. Capture patterns through combinations, transformations, or aggregations\n",
      "3. Are likely to improve classification of \"claim_status\"\n",
      "\n",
      "Also identify any existing features that should be dropped because they:\n",
      "- Are redundant with other features\n",
      "- May cause overfitting\n",
      "- Don't contribute to predicting the target\n",
      "\n",
      "Ensure all generated code uses only existing column names from the df: policy_id, subscription_length, vehicle_age, customer_age, region_code, region_density, segment, model, fuel_type, max_torque, max_power, engine_type, airbags, is_esc, is_adjustable_steering, is_tpms, is_parking_sensors, is_parking_camera, rear_brakes_type, displacement, cylinder, transmission_type, steering_type, turning_radius, length, width, gross_weight, is_front_fog_lights, is_rear_window_wiper, is_rear_window_washer, is_rear_window_defogger, is_brake_assist, is_power_door_locks, is_central_locking, is_power_steering, is_driver_seat_height_adjustable, is_day_night_rear_view_mirror, is_ecw, is_speed_alert, ncap_rating\n",
      "\n",
      "\n",
      "[2025-06-02 22:24:13] INFO:src.modules.fe.CAAFETransformer: \n",
      "\n",
      "→ Invoking LLM for new feature generation...\n",
      "\n",
      "[2025-06-02 22:24:24] INFO:src.modules.fe.CAAFETransformer: \n",
      "🤖 Agent: Detailed statistics on key numeric columns to identify distributions, missing values, and outliers for feature transformations and aggregations.\n",
      "🛠️ Tool Call: `get_column_statistics(column_names=['subscription_length', 'vehicle_age', 'customer_age', 'region_density', 'airbags', 'displacement', 'cylinder', 'turning_radius', 'length', 'width', 'gross_weight', 'ncap_rating'])`\n",
      "\n",
      "[2025-06-02 22:24:24] INFO:src.modules.fe.CAAFETransformer: \n",
      "🤖 Agent: To understand which features have useful info for claim_status prediction, focusing on numerical, categorical but encoded as object - for better feature engineering.\n",
      "🛠️ Tool Call: `get_mutual_information_summary(columns=['subscription_length', 'vehicle_age', 'customer_age', 'region_code', 'region_density', 'segment', 'model', 'fuel_type', 'max_torque', 'max_power', 'engine_type', 'airbags', 'is_esc', 'is_adjustable_steering', 'is_tpms', 'is_parking_sensors', 'is_parking_camera', 'rear_brakes_type', 'displacement', 'cylinder', 'transmission_type', 'steering_type', 'turning_radius', 'length', 'width', 'gross_weight', 'is_front_fog_lights', 'is_rear_window_wiper', 'is_rear_window_washer', 'is_rear_window_defogger', 'is_brake_assist', 'is_power_door_locks', 'is_central_locking', 'is_power_steering', 'is_driver_seat_height_adjustable', 'is_day_night_rear_view_mirror', 'is_ecw', 'is_speed_alert', 'ncap_rating'])`\n",
      "\n",
      "[2025-06-02 22:24:27] INFO:src.modules.fe.CAAFETransformer: \n",
      "🤖 Agent: Detect pairs of highly correlated numeric features that may be redundant for dropping or combining.\n",
      "🛠️ Tool Call: `get_correlation_pairs_summary(columns=['subscription_length', 'vehicle_age', 'customer_age', 'region_density', 'airbags', 'displacement', 'cylinder', 'turning_radius', 'length', 'width', 'gross_weight', 'ncap_rating'])`\n",
      "\n",
      "[2025-06-02 22:24:46] INFO:src.modules.fe.CAAFETransformer: \n",
      "LLM Feature Engineering Reasoning:\n",
      "🤖 Agent: Based on the analyses, I propose the following new features: 1) Extract numeric values from 'max_torque' and 'max_power' to create numeric columns for power and torque metrics. 2) Create interaction feature between vehicle_age and subscription_length capturing policy exposure relative to vehicle age. 3) Feature capturing safety equipment count as a sum of binary safety features to aggregate safety equippedness. 4) Ratio features such as length to width to capture vehicle shape. 5) Bucket 'customer_age' into age groups for non-linear effects. I recommend dropping 'policy_id' since it is an identifier with very low importance and risk of overfitting. Other highly correlated features will be kept since they capture different semantic meanings for the model.\n",
      "[2025-06-02 22:24:46] INFO:src.modules.fe.CAAFETransformer: \n",
      "Proposing 6 new features\n",
      "Dropping 1 existing columns.\n",
      "✅ LLM interaction completed - Iteration 1 took 33.04s\n",
      "[2025-06-02 22:24:46] INFO:src.modules.fe.CAAFETransformer: \n",
      "Generated code snippet:\n",
      "\n",
      "```python\n",
      "# max_torque_nm: Extract max torque value as numeric for better numeric handling and transformations.\n",
      "df['max_torque_nm'] = df['max_torque'].apply(lambda x: float(x.split('Nm@')[0]) if pd.notnull(x) else np.nan)\n",
      "\n",
      "# max_power_bhp: Extract max power in bhp as numeric for use as raw numeric feature.\n",
      "df['max_power_bhp'] = df['max_power'].apply(lambda x: float(x.split('bhp@')[0]) if pd.notnull(x) else np.nan)\n",
      "\n",
      "# vehicle_age_subscription_length_interaction: Interaction between vehicle age and subscription length captures relative usage maturity and potential risk pattern.\n",
      "df['vehicle_age_subscription_length_interaction'] = df['vehicle_age'] * df['subscription_length']\n",
      "\n",
      "# safety_equipment_count: Aggregate binary safety equipment features into a single count of installed features to capture safety level effect.\n",
      "safety_features = ['is_esc', 'is_adjustable_steering', 'is_tpms', 'is_parking_sensors', 'is_parking_camera', 'is_front_fog_lights', 'is_rear_window_wiper', 'is_rear_window_washer', 'is_rear_window_defogger', 'is_brake_assist', 'is_power_door_locks', 'is_central_locking', 'is_power_steering', 'is_driver_seat_height_adjustable', 'is_day_night_rear_view_mirror', 'is_ecw', 'is_speed_alert']\n",
      "for col in safety_features:\n",
      "    df[col] = df[col].map({'Yes': 1, 'No': 0})\n",
      "df['safety_equipment_count'] = df[safety_features].sum(axis=1)\n",
      "\n",
      "# length_to_width_ratio: Ratio of length to width gives an idea of vehicle shape which could impact claim risk.\n",
      "df['length_to_width_ratio'] = df['length'] / df['width']\n",
      "\n",
      "# customer_age_group: Bucket the customer age into categorical groups to capture nonlinear age effects on claim propensity.\n",
      "bins = [30, 40, 50, 60, 70, 80]\n",
      "labels = ['30-39', '40-49', '50-59', '60-69', '70-79']\n",
      "df['customer_age_group'] = pd.cut(df['customer_age'], bins=bins, labels=labels, right=False)\n",
      "\n",
      "# Dropping columns: Drop policy_id to prevent overfitting and since it carries no predictive importance.\n",
      "df.drop(columns=['policy_id'], inplace=True)\n",
      "```\n",
      "[2025-06-02 22:24:46] INFO:src.modules.fe.CAAFETransformer: \n",
      "\n",
      "→ Evaluating incremental benefit of proposed features...\n",
      "\n",
      "[2025-06-02 22:24:54] INFO:src.modules.fe.CAAFETransformer: \n",
      "Feature Evaluation Results (Iteration 1):\n",
      "  Features Added: max_torque_nm, max_power_bhp, vehicle_age_subscription_length_interaction, safety_equipment_count, length_to_width_ratio, customer_age_group\n",
      "  Features Dropped: policy_id\n",
      "  Baseline Metrics: ACC 0.9338, ROC AUC 0.5392\n",
      "  Updated Metrics: ACC 0.9328, ROC AUC 0.5794\n",
      "  Improvements: ACC -0.0009687, ROC AUC +0.04021\n",
      "  Significant: True\n",
      "  Evaluation Time: 8.31s\n",
      "[2025-06-02 22:24:54] INFO:src.modules.fe.CAAFETransformer: \n",
      "✓ Proposed features show improvement: Keeping them. \n",
      "[2025-06-02 22:24:54] INFO:src.modules.fe.CAAFETransformer: \n",
      "ROC AUC +0.04021\n",
      "[2025-06-02 22:24:54] INFO:src.modules.fe.CAAFETransformer: \n",
      "\n",
      "→ Updated dataset shape: (16000, 41) → (16000, 46)\n",
      "\n",
      "[2025-06-02 22:24:54] INFO:src.modules.fe.CAAFETransformer: \n",
      "Iteration 1 completed: \n",
      "Consecutive no improvement: 0, \n",
      "Current best primary metric (accuracy) score: 0.934\n",
      "Current best accuracy score: 0.934\n",
      "Current best ROC AUC score: 0.579\n",
      "[2025-06-02 22:24:54] INFO:src.modules.fe.CAAFETransformer: \n",
      "\n",
      "--- Iteration 2/3 ---\n",
      "\n",
      "[2025-06-02 22:25:22] INFO:src.modules.fe.CAAFETransformer: \n",
      "\n",
      "Prompt for iteration 2:\n",
      "---ITERATION 2---\n",
      "\n",
      "\n",
      "Generate new features to improve classification performance.\n",
      "\n",
      "Dataset description:\n",
      "Insurance claim data.\n",
      "\n",
      "Target variable: claim_status\n",
      "\n",
      "Dataset summary:\n",
      "Dataset shape: 16000 rows, 46 columns\n",
      "Target column: claim_status\n",
      "\n",
      "Columns:\n",
      "- subscription_length (float64): NaN-freq [0.0%], Samples: [0.5, 0.9, 1.5, 0.8, 4.3], Importance: 0.000188\n",
      "- vehicle_age (float64): NaN-freq [0.0%], Samples: [0.0, 2.4, 3.2, 2.6, 0.8], Importance: 0.001438\n",
      "- customer_age (int64): NaN-freq [0.0%], Samples: [47, 38, 39, 49, 58], Importance: 0.000438\n",
      "- region_code (object): NaN-freq [0.0%], Samples: ['C7', 'C2', 'C9', 'C9', 'C14'], Importance: 0.000000\n",
      "- region_density (int64): NaN-freq [0.0%], Samples: [6112, 27003, 17804, 17804, 7788], Importance: 0.000813\n",
      "- segment (object): NaN-freq [0.0%], Samples: ['A', 'B2', 'A', 'C2', 'A'], Importance: 0.000813\n",
      "- model (object): NaN-freq [0.0%], Samples: ['M1', 'M6', 'M3', 'M4', 'M1'], Importance: 0.000438\n",
      "- fuel_type (object): NaN-freq [0.0%], Samples: ['CNG', 'Petrol', 'Petrol', 'Diesel', 'CNG'], Importance: 0.000125\n",
      "- max_torque (object): NaN-freq [0.0%], Samples: ['60Nm@3500rpm', '113Nm@4400rpm', '91Nm@4250rpm', '250Nm@2750rpm', '60Nm@3500rpm'], Importance: 0.000875\n",
      "- max_power (object): NaN-freq [0.0%], Samples: ['40.36bhp@6000rpm', '88.50bhp@6000rpm', '67.06bhp@5500rpm', '113.45bhp@4000rpm', '40.36bhp@6000rpm'], Importance: 0.000375\n",
      "- engine_type (object): NaN-freq [0.0%], Samples: ['F8D Petrol Engine', 'K Series Dual jet', '1.0 SCe', '1.5 L U2 CRDi', 'F8D Petrol Engine'], Importance: -0.000125\n",
      "- airbags (int64): NaN-freq [0.0%], Samples: [2, 2, 2, 6, 2], Importance: 0.000000\n",
      "- is_esc (int64): NaN-freq [0.0%], Samples: [0, 0, 0, 1, 0], Importance: 0.000188\n",
      "- is_adjustable_steering (int64): NaN-freq [0.0%], Samples: [0, 1, 0, 1, 0], Importance: -0.000187\n",
      "- is_tpms (int64): NaN-freq [0.0%], Samples: [0, 0, 0, 1, 0], Importance: 0.000000\n",
      "- is_parking_sensors (int64): NaN-freq [0.0%], Samples: [1, 1, 0, 1, 1], Importance: 0.000000\n",
      "- is_parking_camera (int64): NaN-freq [0.0%], Samples: [0, 0, 1, 1, 0], Importance: 0.000688\n",
      "- rear_brakes_type (object): NaN-freq [0.0%], Samples: ['Drum', 'Drum', 'Drum', 'Disc', 'Drum'], Importance: 0.000000\n",
      "- displacement (int64): NaN-freq [0.0%], Samples: [796, 1197, 999, 1493, 796], Importance: 0.000000\n",
      "- cylinder (int64): NaN-freq [0.0%], Samples: [3, 4, 3, 4, 3], Importance: 0.000625\n",
      "- transmission_type (object): NaN-freq [0.0%], Samples: ['Manual', 'Manual', 'Automatic', 'Automatic', 'Manual'], Importance: 0.000000\n",
      "- steering_type (object): NaN-freq [0.0%], Samples: ['Power', 'Electric', 'Electric', 'Power', 'Power'], Importance: 0.000000\n",
      "- turning_radius (float64): NaN-freq [0.0%], Samples: [4.6, 4.8, 5.0, 5.2, 4.6], Importance: 0.000000\n",
      "- length (int64): NaN-freq [0.0%], Samples: [3445, 3845, 3731, 4300, 3445], Importance: 0.000500\n",
      "- width (int64): NaN-freq [0.0%], Samples: [1515, 1735, 1579, 1790, 1515], Importance: 0.000875\n",
      "- gross_weight (int64): NaN-freq [0.0%], Samples: [1185, 1335, 1155, 1720, 1185], Importance: 0.000250\n",
      "- is_front_fog_lights (int64): NaN-freq [0.0%], Samples: [0, 1, 0, 1, 0], Importance: 0.000000\n",
      "- is_rear_window_wiper (int64): NaN-freq [0.0%], Samples: [0, 0, 0, 1, 0], Importance: 0.000000\n",
      "- is_rear_window_washer (int64): NaN-freq [0.0%], Samples: [0, 0, 0, 1, 0], Importance: 0.000000\n",
      "- is_rear_window_defogger (int64): NaN-freq [0.0%], Samples: [0, 0, 0, 1, 0], Importance: 0.000188\n",
      "- is_brake_assist (int64): NaN-freq [0.0%], Samples: [0, 1, 0, 1, 0], Importance: -0.000062\n",
      "- is_power_door_locks (int64): NaN-freq [0.0%], Samples: [0, 1, 1, 1, 0], Importance: 0.000000\n",
      "- is_central_locking (int64): NaN-freq [0.0%], Samples: [0, 1, 1, 1, 0], Importance: 0.000000\n",
      "- is_power_steering (int64): NaN-freq [0.0%], Samples: [1, 1, 1, 1, 1], Importance: 0.000000\n",
      "- is_driver_seat_height_adjustable (int64): NaN-freq [0.0%], Samples: [0, 1, 0, 1, 0], Importance: 0.000000\n",
      "- is_day_night_rear_view_mirror (int64): NaN-freq [0.0%], Samples: [0, 1, 1, 0, 0], Importance: 0.000563\n",
      "- is_ecw (int64): NaN-freq [0.0%], Samples: [0, 1, 1, 1, 0], Importance: 0.000000\n",
      "- is_speed_alert (int64): NaN-freq [0.0%], Samples: [1, 1, 1, 1, 1], Importance: 0.000000\n",
      "- ncap_rating (int64): NaN-freq [0.0%], Samples: [0, 2, 2, 3, 0], Importance: 0.000250\n",
      "- claim_status (int64): NaN-freq [0.0%], Samples: [0, 0, 0, 0, 0]\n",
      "- max_torque_nm (float64): NaN-freq [0.0%], Samples: [60.0, 113.0, 91.0, 250.0, 60.0], Importance: 0.000000\n",
      "- max_power_bhp (float64): NaN-freq [0.0%], Samples: [40.36, 88.5, 67.06, 113.45, 40.36], Importance: -0.000125\n",
      "- vehicle_age_subscription_length_interaction (float64): NaN-freq [0.0%], Samples: [0.0, 2.16, 4.8, 2.08, 3.44], Importance: 0.001000\n",
      "- safety_equipment_count (int64): NaN-freq [0.0%], Samples: [3, 11, 7, 16, 3], Importance: 0.000313\n",
      "- length_to_width_ratio (float64): NaN-freq [0.0%], Samples: [2.27, 2.22, 2.36, 2.4, 2.27], Importance: -0.000500\n",
      "- customer_age_group (category): NaN-freq [0.0%], Samples: ['40-49', '30-39', '30-39', '40-49', '50-59'], Importance: 0.000500\n",
      "\n",
      "Target distribution: {0: 0.9350625, 1: 0.0649375}\n",
      "\n",
      "Generate up to 5 meaningful features that:\n",
      "1. Add semantic information based on real-world knowledge and df characteristics\n",
      "2. Capture patterns through combinations, transformations, or aggregations\n",
      "3. Are likely to improve classification of \"claim_status\"\n",
      "\n",
      "Also identify any existing features that should be dropped because they:\n",
      "- Are redundant with other features\n",
      "- May cause overfitting\n",
      "- Don't contribute to predicting the target\n",
      "\n",
      "Ensure all generated code uses only existing column names from the df: subscription_length, vehicle_age, customer_age, region_code, region_density, segment, model, fuel_type, max_torque, max_power, engine_type, airbags, is_esc, is_adjustable_steering, is_tpms, is_parking_sensors, is_parking_camera, rear_brakes_type, displacement, cylinder, transmission_type, steering_type, turning_radius, length, width, gross_weight, is_front_fog_lights, is_rear_window_wiper, is_rear_window_washer, is_rear_window_defogger, is_brake_assist, is_power_door_locks, is_central_locking, is_power_steering, is_driver_seat_height_adjustable, is_day_night_rear_view_mirror, is_ecw, is_speed_alert, ncap_rating, max_torque_nm, max_power_bhp, vehicle_age_subscription_length_interaction, safety_equipment_count, length_to_width_ratio, customer_age_group\n",
      "\n",
      "Previous iteration results to take into consideration:\n",
      "Iteration 1\n",
      "Features created: max_torque_nm, max_power_bhp, vehicle_age_subscription_length_interaction, safety_equipment_count, length_to_width_ratio, customer_age_group\n",
      "Features dropped: policy_id\n",
      "Performance before adding features ROC 0.5392, ACC 0.9338.\n",
      "Performance after adding features ROC 0.5794, ACC 0.9328.\n",
      "Improvement ROC +0.04021, ACC -0.0009687.\n",
      "Note: Code was ACCEPTED and applied to the dataset. Columns were successfully added/dropped.\n",
      "Previous iteration reasoning: Based on the analyses, I propose the following new features: 1) Extract numeric values from 'max_torque' and 'max_power' to create numeric columns for power and torque metrics. 2) Create interaction feature between vehicle_age and subscription_length capturing policy exposure relative to vehicle age. 3) Feature capturing safety equipment count as a sum of binary safety features to aggregate safety equippedness. 4) Ratio features such as length to width to capture vehicle shape. 5) Bucket 'customer_age' into age groups for non-linear effects. I recommend dropping 'policy_id' since it is an identifier with very low importance and risk of overfitting. Other highly correlated features will be kept since they capture different semantic meanings for the model.\n",
      "\n",
      "\n",
      "[2025-06-02 22:25:22] INFO:src.modules.fe.CAAFETransformer: \n",
      "\n",
      "→ Invoking LLM for new feature generation...\n",
      "\n",
      "[2025-06-02 22:25:27] INFO:src.modules.fe.CAAFETransformer: \n",
      "🤖 Agent: Identify numeric features strongly correlated with target to guide feature engineering focus\n",
      "🛠️ Tool Call: `get_feature_target_correlations(columns=['subscription_length', 'vehicle_age', 'customer_age', 'region_density', 'airbags', 'displacement', 'cylinder', 'turning_radius', 'length', 'width', 'gross_weight', 'ncap_rating', 'max_torque_nm', 'max_power_bhp', 'vehicle_age_subscription_length_interaction', 'safety_equipment_count', 'length_to_width_ratio'])`\n",
      "\n",
      "[2025-06-02 22:25:27] INFO:src.modules.fe.CAAFETransformer: \n",
      "🤖 Agent: Assess categorical and object type features for their mutual information with the target to guide transformation or encoding strategies\n",
      "🛠️ Tool Call: `get_mutual_information_summary(columns=['region_code', 'segment', 'model', 'fuel_type', 'engine_type', 'rear_brakes_type', 'transmission_type', 'steering_type', 'customer_age_group'])`\n",
      "\n",
      "[2025-06-02 22:25:30] INFO:src.modules.fe.CAAFETransformer: \n",
      "🤖 Agent: Examine detailed statistics, distributions, and imbalance in numeric features that had some correlation or importance signals, to design new transformations or bins.\n",
      "🛠️ Tool Call: `get_column_statistics(column_names=['vehicle_age', 'subscription_length', 'customer_age', 'region_density', 'airbags', 'displacement', 'cylinder', 'turning_radius', 'length', 'width', 'gross_weight', 'ncap_rating', 'max_torque_nm', 'max_power_bhp'])`\n",
      "\n",
      "[2025-06-02 22:25:33] INFO:src.modules.fe.CAAFETransformer: \n",
      "🤖 Agent: Identify highly correlated features to check for redundancy among numeric columns that might be candidates for dropping or combining.\n",
      "🛠️ Tool Call: `get_correlation_pairs_summary(columns=['subscription_length', 'vehicle_age', 'customer_age', 'region_density', 'airbags', 'displacement', 'cylinder', 'turning_radius', 'length', 'width', 'gross_weight', 'ncap_rating', 'max_torque_nm', 'max_power_bhp', 'vehicle_age_subscription_length_interaction', 'safety_equipment_count', 'length_to_width_ratio'])`\n",
      "\n",
      "[2025-06-02 22:25:35] INFO:src.modules.fe.CAAFETransformer: \n",
      "🤖 Agent: Examine max_torque, max_power raw columns' text patterns, to consider alternative numeric features or flags from these columns\n",
      "🛠️ Tool Call: `get_column_statistics(column_names=['max_torque', 'max_power'])`\n",
      "\n",
      "[2025-06-02 22:25:37] INFO:src.modules.fe.CAAFETransformer: \n",
      "🤖 Agent: Check target variable distribution in categorical columns and top frequency categories for possible feature engineering such as rare label consolidation or grouping clusters\n",
      "🛠️ Tool Call: `get_mutual_information_summary(columns=['region_code', 'segment', 'model', 'fuel_type'])`\n",
      "\n",
      "[2025-06-02 22:25:39] INFO:src.modules.fe.CAAFETransformer: \n",
      "🤖 Agent: Review distributions and cardinality for region_code and model columns for possible target-driven encoding or group statistics if warranted\n",
      "🛠️ Tool Call: `get_column_statistics(column_names=['region_code', 'model'])`\n",
      "\n",
      "[2025-06-02 22:25:41] INFO:src.modules.fe.CAAFETransformer: \n",
      "🤖 Agent: Check for presence of outliers in continuous numerical features which may affect model stability and feature engineering choices.\n",
      "🛠️ Tool Call: `check_for_outliers()`\n",
      "\n",
      "[2025-06-02 22:25:56] INFO:src.modules.fe.CAAFETransformer: \n",
      "LLM Feature Engineering Reasoning:\n",
      "🤖 Agent: Based on previous analysis, create new features capturing: 1) interaction ratio of subscription length to vehicle age (policy exposure normalized), 2) normalized torque and power by displacement (performance density), 3) bucket customer_age into finer bins to capture risk age effect, 4) region density log transform to reduce skew and capture urban vs rural effects, 5) combined binary flag for advanced safety features presence. Drop highly correlated redundant feature max_power_bhp due to strong correlation with length and others, and length_to_width_ratio due to very low importance and high correlation with length and width.\n",
      "[2025-06-02 22:25:56] INFO:src.modules.fe.CAAFETransformer: \n",
      "Proposing 6 new features\n",
      "Dropping 2 existing columns.\n",
      "✅ LLM interaction completed - Iteration 2 took 34.27s\n",
      "[2025-06-02 22:25:56] INFO:src.modules.fe.CAAFETransformer: \n",
      "Generated code snippet:\n",
      "\n",
      "```python\n",
      "# subscription_to_vehicle_age_ratio: Create normalized exposure feature that expresses subscription length relative to vehicle age to capture risk duration adjusted for vehicle age\n",
      "df['subscription_to_vehicle_age_ratio'] = df['subscription_length'] / (df['vehicle_age'] + 1)  # +1 to avoid division by zero\n",
      "\n",
      "# torque_to_displacement_ratio: Create performance density features by normalizing max_torque_nm and max_power_bhp by displacement, to capture vehicle power efficiency characteristics\n",
      "df['torque_to_displacement_ratio'] = df['max_torque_nm'] / df['displacement']\n",
      "\n",
      "# power_to_displacement_ratio: df['power_to_displacement_ratio'] = df['max_power_bhp'] / df['displacement']\n",
      "df['power_to_displacement_ratio'] = df['max_power_bhp'] / df['displacement']\n",
      "\n",
      "# customer_age_fine_group: Create finer age groups than existing customer_age_group capturing nuanced age risks\n",
      "bins = [34, 39, 44, 49, 54, 59, 75]\n",
      "labels = ['35-39', '40-44', '45-49', '50-54', '55-59', '60+']\n",
      "df['customer_age_fine_group'] = pd.cut(df['customer_age'], bins=bins, labels=labels, right=True, include_lowest=True)\n",
      "\n",
      "# log_region_density: Reduce skew for region_density with log transform to capture diminishing effect of region density on claims\n",
      "df['log_region_density'] = np.log1p(df['region_density'])\n",
      "\n",
      "# has_advanced_safety_features: Combine multiple binary safety features into one aggregated binary flag for advanced safety equipment presence\n",
      "df['has_advanced_safety_features'] = ((df['is_esc'] + df['is_tpms'] + df['is_parking_camera'] + df['is_brake_assist']) > 0).astype(int)\n",
      "\n",
      "# Dropping columns: Drop redundant and low importance columns highly correlated with other features after creating new informative features.\n",
      "df.drop(columns=['max_power_bhp'], inplace=True)\n",
      "df.drop(columns=['length_to_width_ratio'], inplace=True)\n",
      "```\n",
      "[2025-06-02 22:25:56] INFO:src.modules.fe.CAAFETransformer: \n",
      "\n",
      "→ Evaluating incremental benefit of proposed features...\n",
      "\n",
      "[2025-06-02 22:26:06] INFO:src.modules.fe.CAAFETransformer: \n",
      "Feature Evaluation Results (Iteration 2):\n",
      "  Features Added: subscription_to_vehicle_age_ratio, torque_to_displacement_ratio, power_to_displacement_ratio, customer_age_fine_group, log_region_density, has_advanced_safety_features\n",
      "  Features Dropped: max_power_bhp, length_to_width_ratio\n",
      "  Baseline Metrics: ACC 0.9328, ROC AUC 0.5794\n",
      "  Updated Metrics: ACC 0.9326, ROC AUC 0.58\n",
      "  Improvements: ACC -0.0002813, ROC AUC +0.0006632\n",
      "  Significant: True\n",
      "  Evaluation Time: 9.78s\n",
      "[2025-06-02 22:26:06] INFO:src.modules.fe.CAAFETransformer: \n",
      "✓ Proposed features show improvement: Keeping them. \n",
      "[2025-06-02 22:26:06] INFO:src.modules.fe.CAAFETransformer: \n",
      "ROC AUC +0.0006632\n",
      "[2025-06-02 22:26:06] INFO:src.modules.fe.CAAFETransformer: \n",
      "\n",
      "→ Updated dataset shape: (16000, 46) → (16000, 50)\n",
      "\n",
      "[2025-06-02 22:26:06] INFO:src.modules.fe.CAAFETransformer: \n",
      "Iteration 2 completed: \n",
      "Consecutive no improvement: 0, \n",
      "Current best primary metric (accuracy) score: 0.934\n",
      "Current best accuracy score: 0.934\n",
      "Current best ROC AUC score: 0.580\n",
      "[2025-06-02 22:26:06] INFO:src.modules.fe.CAAFETransformer: \n",
      "\n",
      "--- Iteration 3/3 ---\n",
      "\n",
      "[2025-06-02 22:26:37] INFO:src.modules.fe.CAAFETransformer: \n",
      "\n",
      "Prompt for iteration 3:\n",
      "---ITERATION 3---\n",
      "\n",
      "\n",
      "Generate new features to improve classification performance.\n",
      "\n",
      "Dataset description:\n",
      "Insurance claim data.\n",
      "\n",
      "Target variable: claim_status\n",
      "\n",
      "Dataset summary:\n",
      "Dataset shape: 16000 rows, 50 columns\n",
      "Target column: claim_status\n",
      "\n",
      "Columns:\n",
      "- subscription_length (float64): NaN-freq [0.0%], Samples: [0.5, 0.9, 1.5, 0.8, 4.3], Importance: -0.000063\n",
      "- vehicle_age (float64): NaN-freq [0.0%], Samples: [0.0, 2.4, 3.2, 2.6, 0.8], Importance: -0.001000\n",
      "- customer_age (int64): NaN-freq [0.0%], Samples: [47, 38, 39, 49, 58], Importance: -0.000625\n",
      "- region_code (object): NaN-freq [0.0%], Samples: ['C7', 'C2', 'C9', 'C9', 'C14'], Importance: -0.000750\n",
      "- region_density (int64): NaN-freq [0.0%], Samples: [6112, 27003, 17804, 17804, 7788], Importance: 0.000000\n",
      "- segment (object): NaN-freq [0.0%], Samples: ['A', 'B2', 'A', 'C2', 'A'], Importance: -0.000250\n",
      "- model (object): NaN-freq [0.0%], Samples: ['M1', 'M6', 'M3', 'M4', 'M1'], Importance: 0.000250\n",
      "- fuel_type (object): NaN-freq [0.0%], Samples: ['CNG', 'Petrol', 'Petrol', 'Diesel', 'CNG'], Importance: -0.000063\n",
      "- max_torque (object): NaN-freq [0.0%], Samples: ['60Nm@3500rpm', '113Nm@4400rpm', '91Nm@4250rpm', '250Nm@2750rpm', '60Nm@3500rpm'], Importance: -0.000250\n",
      "- max_power (object): NaN-freq [0.0%], Samples: ['40.36bhp@6000rpm', '88.50bhp@6000rpm', '67.06bhp@5500rpm', '113.45bhp@4000rpm', '40.36bhp@6000rpm'], Importance: -0.000625\n",
      "- engine_type (object): NaN-freq [0.0%], Samples: ['F8D Petrol Engine', 'K Series Dual jet', '1.0 SCe', '1.5 L U2 CRDi', 'F8D Petrol Engine'], Importance: -0.000125\n",
      "- airbags (int64): NaN-freq [0.0%], Samples: [2, 2, 2, 6, 2], Importance: 0.000000\n",
      "- is_esc (int64): NaN-freq [0.0%], Samples: [0, 0, 0, 1, 0], Importance: -0.000437\n",
      "- is_adjustable_steering (int64): NaN-freq [0.0%], Samples: [0, 1, 0, 1, 0], Importance: 0.000062\n",
      "- is_tpms (int64): NaN-freq [0.0%], Samples: [0, 0, 0, 1, 0], Importance: 0.000000\n",
      "- is_parking_sensors (int64): NaN-freq [0.0%], Samples: [1, 1, 0, 1, 1], Importance: 0.000000\n",
      "- is_parking_camera (int64): NaN-freq [0.0%], Samples: [0, 0, 1, 1, 0], Importance: -0.000563\n",
      "- rear_brakes_type (object): NaN-freq [0.0%], Samples: ['Drum', 'Drum', 'Drum', 'Disc', 'Drum'], Importance: 0.000000\n",
      "- displacement (int64): NaN-freq [0.0%], Samples: [796, 1197, 999, 1493, 796], Importance: 0.000000\n",
      "- cylinder (int64): NaN-freq [0.0%], Samples: [3, 4, 3, 4, 3], Importance: -0.000688\n",
      "- transmission_type (object): NaN-freq [0.0%], Samples: ['Manual', 'Manual', 'Automatic', 'Automatic', 'Manual'], Importance: 0.000000\n",
      "- steering_type (object): NaN-freq [0.0%], Samples: ['Power', 'Electric', 'Electric', 'Power', 'Power'], Importance: 0.000000\n",
      "- turning_radius (float64): NaN-freq [0.0%], Samples: [4.6, 4.8, 5.0, 5.2, 4.6], Importance: -0.000938\n",
      "- length (int64): NaN-freq [0.0%], Samples: [3445, 3845, 3731, 4300, 3445], Importance: -0.000813\n",
      "- width (int64): NaN-freq [0.0%], Samples: [1515, 1735, 1579, 1790, 1515], Importance: -0.000375\n",
      "- gross_weight (int64): NaN-freq [0.0%], Samples: [1185, 1335, 1155, 1720, 1185], Importance: -0.000437\n",
      "- is_front_fog_lights (int64): NaN-freq [0.0%], Samples: [0, 1, 0, 1, 0], Importance: 0.000000\n",
      "- is_rear_window_wiper (int64): NaN-freq [0.0%], Samples: [0, 0, 0, 1, 0], Importance: 0.000000\n",
      "- is_rear_window_washer (int64): NaN-freq [0.0%], Samples: [0, 0, 0, 1, 0], Importance: 0.000000\n",
      "- is_rear_window_defogger (int64): NaN-freq [0.0%], Samples: [0, 0, 0, 1, 0], Importance: 0.000062\n",
      "- is_brake_assist (int64): NaN-freq [0.0%], Samples: [0, 1, 0, 1, 0], Importance: 0.000000\n",
      "- is_power_door_locks (int64): NaN-freq [0.0%], Samples: [0, 1, 1, 1, 0], Importance: 0.000000\n",
      "- is_central_locking (int64): NaN-freq [0.0%], Samples: [0, 1, 1, 1, 0], Importance: 0.000000\n",
      "- is_power_steering (int64): NaN-freq [0.0%], Samples: [1, 1, 1, 1, 1], Importance: 0.000000\n",
      "- is_driver_seat_height_adjustable (int64): NaN-freq [0.0%], Samples: [0, 1, 0, 1, 0], Importance: 0.000000\n",
      "- is_day_night_rear_view_mirror (int64): NaN-freq [0.0%], Samples: [0, 1, 1, 0, 0], Importance: -0.000125\n",
      "- is_ecw (int64): NaN-freq [0.0%], Samples: [0, 1, 1, 1, 0], Importance: 0.000000\n",
      "- is_speed_alert (int64): NaN-freq [0.0%], Samples: [1, 1, 1, 1, 1], Importance: 0.000000\n",
      "- ncap_rating (int64): NaN-freq [0.0%], Samples: [0, 2, 2, 3, 0], Importance: -0.000125\n",
      "- claim_status (int64): NaN-freq [0.0%], Samples: [0, 0, 0, 0, 0]\n",
      "- max_torque_nm (float64): NaN-freq [0.0%], Samples: [60.0, 113.0, 91.0, 250.0, 60.0], Importance: 0.000000\n",
      "- vehicle_age_subscription_length_interaction (float64): NaN-freq [0.0%], Samples: [0.0, 2.16, 4.8, 2.08, 3.44], Importance: -0.000375\n",
      "- safety_equipment_count (int64): NaN-freq [0.0%], Samples: [3, 11, 7, 16, 3], Importance: -0.000563\n",
      "- customer_age_group (category): NaN-freq [0.0%], Samples: ['40-49', '30-39', '30-39', '40-49', '50-59'], Importance: -0.000625\n",
      "- subscription_to_vehicle_age_ratio (float64): NaN-freq [0.0%], Samples: [0.5, 0.26, 0.36, 0.22, 2.39], Importance: -0.001125\n",
      "- torque_to_displacement_ratio (float64): NaN-freq [0.0%], Samples: [0.08, 0.09, 0.09, 0.17, 0.08], Importance: 0.000000\n",
      "- power_to_displacement_ratio (float64): NaN-freq [0.0%], Samples: [0.05, 0.07, 0.07, 0.08, 0.05], Importance: -0.000563\n",
      "- customer_age_fine_group (category): NaN-freq [0.0%], Samples: ['45-49', '35-39', '35-39', '45-49', '55-59'], Importance: -0.000375\n",
      "- log_region_density (float64): NaN-freq [0.0%], Samples: [8.72, 10.2, 9.79, 9.79, 8.96], Importance: 0.000000\n",
      "- has_advanced_safety_features (int64): NaN-freq [0.0%], Samples: [0, 1, 1, 1, 0], Importance: 0.000000\n",
      "\n",
      "Target distribution: {0: 0.9350625, 1: 0.0649375}\n",
      "\n",
      "Generate up to 5 meaningful features that:\n",
      "1. Add semantic information based on real-world knowledge and df characteristics\n",
      "2. Capture patterns through combinations, transformations, or aggregations\n",
      "3. Are likely to improve classification of \"claim_status\"\n",
      "\n",
      "Also identify any existing features that should be dropped because they:\n",
      "- Are redundant with other features\n",
      "- May cause overfitting\n",
      "- Don't contribute to predicting the target\n",
      "\n",
      "Ensure all generated code uses only existing column names from the df: subscription_length, vehicle_age, customer_age, region_code, region_density, segment, model, fuel_type, max_torque, max_power, engine_type, airbags, is_esc, is_adjustable_steering, is_tpms, is_parking_sensors, is_parking_camera, rear_brakes_type, displacement, cylinder, transmission_type, steering_type, turning_radius, length, width, gross_weight, is_front_fog_lights, is_rear_window_wiper, is_rear_window_washer, is_rear_window_defogger, is_brake_assist, is_power_door_locks, is_central_locking, is_power_steering, is_driver_seat_height_adjustable, is_day_night_rear_view_mirror, is_ecw, is_speed_alert, ncap_rating, max_torque_nm, vehicle_age_subscription_length_interaction, safety_equipment_count, customer_age_group, subscription_to_vehicle_age_ratio, torque_to_displacement_ratio, power_to_displacement_ratio, customer_age_fine_group, log_region_density, has_advanced_safety_features\n",
      "\n",
      "Previous iteration results to take into consideration:\n",
      "Iteration 2\n",
      "Features created: subscription_to_vehicle_age_ratio, torque_to_displacement_ratio, power_to_displacement_ratio, customer_age_fine_group, log_region_density, has_advanced_safety_features\n",
      "Features dropped: max_power_bhp, length_to_width_ratio\n",
      "Performance before adding features ROC 0.5794, ACC 0.9328.\n",
      "Performance after adding features ROC 0.58, ACC 0.9326.\n",
      "Improvement ROC +0.0006632, ACC -0.0002813.\n",
      "Note: Code was ACCEPTED and applied to the dataset. Columns were successfully added/dropped.\n",
      "Previous iteration reasoning: Based on previous analysis, create new features capturing: 1) interaction ratio of subscription length to vehicle age (policy exposure normalized), 2) normalized torque and power by displacement (performance density), 3) bucket customer_age into finer bins to capture risk age effect, 4) region density log transform to reduce skew and capture urban vs rural effects, 5) combined binary flag for advanced safety features presence. Drop highly correlated redundant feature max_power_bhp due to strong correlation with length and others, and length_to_width_ratio due to very low importance and high correlation with length and width.\n",
      "\n",
      "\n",
      "[2025-06-02 22:26:37] INFO:src.modules.fe.CAAFETransformer: \n",
      "\n",
      "→ Invoking LLM for new feature generation...\n",
      "\n",
      "[2025-06-02 22:26:42] INFO:src.modules.fe.CAAFETransformer: \n",
      "🤖 Agent: To generate meaningful new features, get detailed statistics of top numerical features with importance close to or above zero and relevant existing engineered features for claims prediction.\n",
      "🛠️ Tool Call: `get_column_statistics(column_names=['subscription_length', 'vehicle_age', 'customer_age', 'region_density', 'max_torque_nm', 'displacement', 'cylinder', 'airbags', 'ncap_rating', 'vehicle_age_subscription_length_interaction', 'safety_equipment_count'])`\n",
      "\n",
      "[2025-06-02 22:26:42] INFO:src.modules.fe.CAAFETransformer: \n",
      "🤖 Agent: Check mutual information to identify non-linear predictive relations between features and target claim_status.\n",
      "🛠️ Tool Call: `get_mutual_information_summary(columns=['subscription_length', 'vehicle_age', 'customer_age', 'region_density', 'max_torque_nm', 'displacement', 'cylinder', 'airbags', 'ncap_rating', 'vehicle_age_subscription_length_interaction', 'safety_equipment_count'])`\n",
      "\n",
      "[2025-06-02 22:26:46] INFO:src.modules.fe.CAAFETransformer: \n",
      "🤖 Agent: Check for highly correlated numeric features to avoid redundant feature creation given many features are ratios or collections of safety features.\n",
      "🛠️ Tool Call: `get_correlation_pairs_summary(columns=['subscription_length', 'vehicle_age', 'customer_age', 'region_density', 'max_torque_nm', 'displacement', 'cylinder', 'airbags', 'ncap_rating', 'vehicle_age_subscription_length_interaction', 'safety_equipment_count', 'subscription_to_vehicle_age_ratio', 'torque_to_displacement_ratio', 'power_to_displacement_ratio'])`\n",
      "\n",
      "[2025-06-02 22:26:58] INFO:src.modules.fe.CAAFETransformer: \n",
      "LLM Feature Engineering Reasoning:\n",
      "🤖 Agent: Based on statistics, mutual information, and correlation analysis, I propose 5 new features:\n",
      "1. Age gap: difference between customer_age and vehicle_age to capture risk from customer-vehicle age gap.\n",
      "2. Engine power density: max_torque_nm divided by displacement to capture torque efficiency.\n",
      "3. Safety feature interaction: combine safety_equipment_count and airbags to capture cumulative safety effect.\n",
      "4. Subscription length bucket: categorize subscription_length into bins capturing policy length effects.\n",
      "5. Segment frequency encoding: frequency of segment to encode risk from segment categories.\n",
      "\n",
      "Drop features:\n",
      "- drop 'vehicle_age_subscription_length_interaction' due to very high skew and no performance gain,\n",
      "- drop 'torque_to_displacement_ratio' as it is extremely correlated with max_torque and displacement and low importance,\n",
      "- drop 'power_to_displacement_ratio' and 'safety_equipment_count' because of high correlation among them and low importance,\n",
      "- drop 'customer_age_fine_group' since it had no performance gain in prior iterations.\n",
      "[2025-06-02 22:26:58] INFO:src.modules.fe.CAAFETransformer: \n",
      "Proposing 5 new features\n",
      "Dropping 5 existing columns.\n",
      "✅ LLM interaction completed - Iteration 3 took 20.80s\n",
      "[2025-06-02 22:26:58] INFO:src.modules.fe.CAAFETransformer: \n",
      "Generated code snippet:\n",
      "\n",
      "```python\n",
      "# age_gap: Customer and vehicle age difference captures mismatch risk, may improve prediction.\n",
      "df['age_gap'] = df['customer_age'] - df['vehicle_age']\n",
      "\n",
      "# engine_power_density: Engine torque efficiency indicator, normalized by displacement to reflect mechanical efficiency.\n",
      "df['engine_power_density'] = df['max_torque_nm'] / df['displacement']\n",
      "\n",
      "# safety_airbags_interaction: Interaction of airbags and total safety equipment count to capture combined safety effect more granularly.\n",
      "df['safety_airbags_interaction'] = df['airbags'] * df['safety_equipment_count']\n",
      "\n",
      "# subscription_length_bucket: Bucket subscription length into bins to identify policy length risk segments.\n",
      "df['subscription_length_bucket'] = pd.cut(df['subscription_length'], bins=[0,2,5,10,15], labels=['Short','Medium','Long','Very Long'], include_lowest=True)\n",
      "\n",
      "# freq_segment: Frequency encoding of segment to capture distribution-related risk patterns.\n",
      "segment_freq = df['segment'].value_counts(normalize=True)\n",
      "df['freq_segment'] = df['segment'].map(segment_freq)\n",
      "\n",
      "# Dropping columns: Dropping strongly correlated or uninformative features to reduce multicollinearity and overfitting risk.\n",
      "df.drop(columns=['vehicle_age_subscription_length_interaction'], inplace=True)\n",
      "df.drop(columns=['torque_to_displacement_ratio'], inplace=True)\n",
      "df.drop(columns=['power_to_displacement_ratio'], inplace=True)\n",
      "df.drop(columns=['safety_equipment_count'], inplace=True)\n",
      "df.drop(columns=['customer_age_fine_group'], inplace=True)\n",
      "```\n",
      "[2025-06-02 22:26:58] INFO:src.modules.fe.CAAFETransformer: \n",
      "\n",
      "→ Evaluating incremental benefit of proposed features...\n",
      "\n",
      "[2025-06-02 22:27:09] INFO:src.modules.fe.CAAFETransformer: \n",
      "Feature Evaluation Results (Iteration 3):\n",
      "  Features Added: age_gap, engine_power_density, safety_airbags_interaction, subscription_length_bucket, freq_segment\n",
      "  Features Dropped: vehicle_age_subscription_length_interaction, torque_to_displacement_ratio, power_to_displacement_ratio, safety_equipment_count, customer_age_fine_group\n",
      "  Baseline Metrics: ACC 0.9326, ROC AUC 0.58\n",
      "  Updated Metrics: ACC 0.9319, ROC AUC 0.5802\n",
      "  Improvements: ACC -0.000625, ROC AUC +0.0001427\n",
      "  Significant: True\n",
      "  Evaluation Time: 10.66s\n",
      "[2025-06-02 22:27:09] INFO:src.modules.fe.CAAFETransformer: \n",
      "✓ Proposed features show improvement: Keeping them. \n",
      "[2025-06-02 22:27:09] INFO:src.modules.fe.CAAFETransformer: \n",
      "ROC AUC +0.0001427\n",
      "[2025-06-02 22:27:09] INFO:src.modules.fe.CAAFETransformer: \n",
      "\n",
      "→ Updated dataset shape: (16000, 50) → (16000, 50)\n",
      "\n",
      "[2025-06-02 22:27:09] INFO:src.modules.fe.CAAFETransformer: \n",
      "Iteration 3 completed: \n",
      "Consecutive no improvement: 0, \n",
      "Current best primary metric (accuracy) score: 0.934\n",
      "Current best accuracy score: 0.934\n",
      "Current best ROC AUC score: 0.580\n",
      "[2025-06-02 22:27:09] INFO:src.modules.fe.CAAFETransformer: \n",
      "Final summary: \n",
      "Total iterations=3, \n",
      "Features created, max_torque_nm, max_power_bhp, vehicle_age_subscription_length_interaction, safety_equipment_count, length_to_width_ratio, customer_age_group, subscription_to_vehicle_age_ratio, torque_to_displacement_ratio, power_to_displacement_ratio, customer_age_fine_group, log_region_density, has_advanced_safety_features, age_gap, engine_power_density, safety_airbags_interaction, subscription_length_bucket, freq_segment\n",
      "Features dropped, policy_id, max_power_bhp, length_to_width_ratio, vehicle_age_subscription_length_interaction, torque_to_displacement_ratio, power_to_displacement_ratio, safety_equipment_count, customer_age_fine_group\n",
      "Features rejected, \n",
      "Original ROC AUC: 0.5391516080443717, \n",
      "Original accuracy: 0.9338124990463257, \n",
      "Final ROC AUC: 0.5801638145345025, \n",
      "Final accuracy: 0.9338124990463257, \n",
      "Total duration=207.8818736076355\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CAAFETransformer(base_classifier=XGBClassifier(base_score=None, booster=None,\n",
       "                                               callbacks=None,\n",
       "                                               colsample_bylevel=None,\n",
       "                                               colsample_bynode=None,\n",
       "                                               colsample_bytree=None,\n",
       "                                               device=None,\n",
       "                                               early_stopping_rounds=None,\n",
       "                                               enable_categorical=True,\n",
       "                                               eval_metric=&#x27;logloss&#x27;,\n",
       "                                               feature_types=None,\n",
       "                                               feature_weights=None, gamma=None,\n",
       "                                               grow_policy=None,\n",
       "                                               importance_type=None,\n",
       "                                               interaction_constr...\n",
       "                                               max_depth=None, max_leaves=None,\n",
       "                                               min_child_weight=None,\n",
       "                                               missing=nan,\n",
       "                                               monotone_constraints=None,\n",
       "                                               multi_strategy=None,\n",
       "                                               n_estimators=None, n_jobs=-1,\n",
       "                                               num_parallel_tree=None, ...),\n",
       "                 dataset_description=&#x27;Insurance claim data.&#x27;, iterations=3,\n",
       "                 llm_model=&#x27;gpt-4.1-mini&#x27;,\n",
       "                 logger=&lt;Logger src.modules.fe.CAAFETransformer (INFO)&gt;,\n",
       "                 max_features=5, n_splits=5, random_state=123,\n",
       "                 target_name=&#x27;claim_status&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>CAAFETransformer</div></div><div><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>CAAFETransformer(base_classifier=XGBClassifier(base_score=None, booster=None,\n",
       "                                               callbacks=None,\n",
       "                                               colsample_bylevel=None,\n",
       "                                               colsample_bynode=None,\n",
       "                                               colsample_bytree=None,\n",
       "                                               device=None,\n",
       "                                               early_stopping_rounds=None,\n",
       "                                               enable_categorical=True,\n",
       "                                               eval_metric=&#x27;logloss&#x27;,\n",
       "                                               feature_types=None,\n",
       "                                               feature_weights=None, gamma=None,\n",
       "                                               grow_policy=None,\n",
       "                                               importance_type=None,\n",
       "                                               interaction_constr...\n",
       "                                               max_depth=None, max_leaves=None,\n",
       "                                               min_child_weight=None,\n",
       "                                               missing=nan,\n",
       "                                               monotone_constraints=None,\n",
       "                                               multi_strategy=None,\n",
       "                                               n_estimators=None, n_jobs=-1,\n",
       "                                               num_parallel_tree=None, ...),\n",
       "                 dataset_description=&#x27;Insurance claim data.&#x27;, iterations=3,\n",
       "                 llm_model=&#x27;gpt-4.1-mini&#x27;,\n",
       "                 logger=&lt;Logger src.modules.fe.CAAFETransformer (INFO)&gt;,\n",
       "                 max_features=5, n_splits=5, random_state=123,\n",
       "                 target_name=&#x27;claim_status&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>base_classifier: XGBClassifier</div></div></label><div class=\"sk-toggleable__content \"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content \"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "CAAFETransformer(base_classifier=XGBClassifier(base_score=None, booster=None,\n",
       "                                               callbacks=None,\n",
       "                                               colsample_bylevel=None,\n",
       "                                               colsample_bynode=None,\n",
       "                                               colsample_bytree=None,\n",
       "                                               device=None,\n",
       "                                               early_stopping_rounds=None,\n",
       "                                               enable_categorical=True,\n",
       "                                               eval_metric='logloss',\n",
       "                                               feature_types=None,\n",
       "                                               feature_weights=None, gamma=None,\n",
       "                                               grow_policy=None,\n",
       "                                               importance_type=None,\n",
       "                                               interaction_constr...\n",
       "                                               max_depth=None, max_leaves=None,\n",
       "                                               min_child_weight=None,\n",
       "                                               missing=nan,\n",
       "                                               monotone_constraints=None,\n",
       "                                               multi_strategy=None,\n",
       "                                               n_estimators=None, n_jobs=-1,\n",
       "                                               num_parallel_tree=None, ...),\n",
       "                 dataset_description='Insurance claim data.', iterations=3,\n",
       "                 llm_model='gpt-4.1-mini',\n",
       "                 logger=<Logger src.modules.fe.CAAFETransformer (INFO)>,\n",
       "                 max_features=5, n_splits=5, random_state=123,\n",
       "                 target_name='claim_status')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe.fit(X_train, y_train, show_prompts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-06-02 22:29:02] INFO:src.modules.fe.CAAFETransformer: Feature-generation code saved to features.py\n"
     ]
    }
   ],
   "source": [
    "fe.save_code(\"features.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Usage(requests=2, request_tokens=9502, response_tokens=1124, total_tokens=10626, details={'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0, 'cached_tokens': 3712}),\n",
       " Usage(requests=8, request_tokens=51405, response_tokens=1168, total_tokens=52573, details={'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0, 'cached_tokens': 44672}),\n",
       " Usage(requests=3, request_tokens=16621, response_tokens=841, total_tokens=17462, details={'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0, 'cached_tokens': 11520})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe.usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Features created: max_torque_nm, max_power_bhp, vehicle_age_subscription_length_interaction, safety_equipment_count, length_to_width_ratio, customer_age_group\n",
      "Features dropped: policy_id\n",
      "Performance before adding features ROC 0.5392, ACC 0.9338.\n",
      "Performance after adding features ROC 0.5794, ACC 0.9328.\n",
      "Improvement ROC +0.04021, ACC -0.0009687.\n",
      "Note: Code was ACCEPTED and applied to the dataset. Columns were successfully added/dropped.\n",
      "\n",
      "Iteration 2\n",
      "Features created: subscription_to_vehicle_age_ratio, torque_to_displacement_ratio, power_to_displacement_ratio, customer_age_fine_group, log_region_density, has_advanced_safety_features\n",
      "Features dropped: max_power_bhp, length_to_width_ratio\n",
      "Performance before adding features ROC 0.5794, ACC 0.9328.\n",
      "Performance after adding features ROC 0.58, ACC 0.9326.\n",
      "Improvement ROC +0.0006632, ACC -0.0002813.\n",
      "Note: Code was ACCEPTED and applied to the dataset. Columns were successfully added/dropped.\n",
      "\n",
      "Iteration 3\n",
      "Features created: age_gap, engine_power_density, safety_airbags_interaction, subscription_length_bucket, freq_segment\n",
      "Features dropped: vehicle_age_subscription_length_interaction, torque_to_displacement_ratio, power_to_displacement_ratio, safety_equipment_count, customer_age_fine_group\n",
      "Performance before adding features ROC 0.58, ACC 0.9326.\n",
      "Performance after adding features ROC 0.5802, ACC 0.9319.\n",
      "Improvement ROC +0.0001427, ACC -0.000625.\n",
      "Note: Code was ACCEPTED and applied to the dataset. Columns were successfully added/dropped.\n"
     ]
    }
   ],
   "source": [
    "print(fe.get_formatted_agent_notepad(n=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 49)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subscription_length</th>\n",
       "      <th>vehicle_age</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>region_code</th>\n",
       "      <th>region_density</th>\n",
       "      <th>segment</th>\n",
       "      <th>model</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>max_torque</th>\n",
       "      <th>max_power</th>\n",
       "      <th>...</th>\n",
       "      <th>max_torque_nm</th>\n",
       "      <th>customer_age_group</th>\n",
       "      <th>subscription_to_vehicle_age_ratio</th>\n",
       "      <th>log_region_density</th>\n",
       "      <th>has_advanced_safety_features</th>\n",
       "      <th>age_gap</th>\n",
       "      <th>engine_power_density</th>\n",
       "      <th>safety_airbags_interaction</th>\n",
       "      <th>subscription_length_bucket</th>\n",
       "      <th>freq_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7047</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47</td>\n",
       "      <td>C7</td>\n",
       "      <td>6112</td>\n",
       "      <td>A</td>\n",
       "      <td>M1</td>\n",
       "      <td>CNG</td>\n",
       "      <td>60Nm@3500rpm</td>\n",
       "      <td>40.36bhp@6000rpm</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>40-49</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.718173</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.075377</td>\n",
       "      <td>6</td>\n",
       "      <td>Short</td>\n",
       "      <td>0.295938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25110</th>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>38</td>\n",
       "      <td>C2</td>\n",
       "      <td>27003</td>\n",
       "      <td>B2</td>\n",
       "      <td>M6</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>113Nm@4400rpm</td>\n",
       "      <td>88.50bhp@6000rpm</td>\n",
       "      <td>...</td>\n",
       "      <td>113.0</td>\n",
       "      <td>30-39</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>10.203740</td>\n",
       "      <td>1</td>\n",
       "      <td>35.6</td>\n",
       "      <td>0.094403</td>\n",
       "      <td>22</td>\n",
       "      <td>Short</td>\n",
       "      <td>0.313625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58586</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>39</td>\n",
       "      <td>C9</td>\n",
       "      <td>17804</td>\n",
       "      <td>A</td>\n",
       "      <td>M3</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>91Nm@4250rpm</td>\n",
       "      <td>67.06bhp@5500rpm</td>\n",
       "      <td>...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>30-39</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>9.787235</td>\n",
       "      <td>1</td>\n",
       "      <td>35.8</td>\n",
       "      <td>0.091091</td>\n",
       "      <td>14</td>\n",
       "      <td>Short</td>\n",
       "      <td>0.295938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56582</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>49</td>\n",
       "      <td>C9</td>\n",
       "      <td>17804</td>\n",
       "      <td>C2</td>\n",
       "      <td>M4</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>250Nm@2750rpm</td>\n",
       "      <td>113.45bhp@4000rpm</td>\n",
       "      <td>...</td>\n",
       "      <td>250.0</td>\n",
       "      <td>40-49</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>9.787235</td>\n",
       "      <td>1</td>\n",
       "      <td>46.4</td>\n",
       "      <td>0.167448</td>\n",
       "      <td>96</td>\n",
       "      <td>Short</td>\n",
       "      <td>0.238375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5304</th>\n",
       "      <td>4.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>58</td>\n",
       "      <td>C14</td>\n",
       "      <td>7788</td>\n",
       "      <td>A</td>\n",
       "      <td>M1</td>\n",
       "      <td>CNG</td>\n",
       "      <td>60Nm@3500rpm</td>\n",
       "      <td>40.36bhp@6000rpm</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50-59</td>\n",
       "      <td>2.388889</td>\n",
       "      <td>8.960468</td>\n",
       "      <td>0</td>\n",
       "      <td>57.2</td>\n",
       "      <td>0.075377</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0.295938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       subscription_length  vehicle_age  customer_age region_code  \\\n",
       "7047                   0.5          0.0            47          C7   \n",
       "25110                  0.9          2.4            38          C2   \n",
       "58586                  1.5          3.2            39          C9   \n",
       "56582                  0.8          2.6            49          C9   \n",
       "5304                   4.3          0.8            58         C14   \n",
       "\n",
       "       region_density segment model fuel_type     max_torque  \\\n",
       "7047             6112       A    M1       CNG   60Nm@3500rpm   \n",
       "25110           27003      B2    M6    Petrol  113Nm@4400rpm   \n",
       "58586           17804       A    M3    Petrol   91Nm@4250rpm   \n",
       "56582           17804      C2    M4    Diesel  250Nm@2750rpm   \n",
       "5304             7788       A    M1       CNG   60Nm@3500rpm   \n",
       "\n",
       "               max_power  ... max_torque_nm  customer_age_group  \\\n",
       "7047    40.36bhp@6000rpm  ...          60.0               40-49   \n",
       "25110   88.50bhp@6000rpm  ...         113.0               30-39   \n",
       "58586   67.06bhp@5500rpm  ...          91.0               30-39   \n",
       "56582  113.45bhp@4000rpm  ...         250.0               40-49   \n",
       "5304    40.36bhp@6000rpm  ...          60.0               50-59   \n",
       "\n",
       "       subscription_to_vehicle_age_ratio  log_region_density  \\\n",
       "7047                            0.500000            8.718173   \n",
       "25110                           0.264706           10.203740   \n",
       "58586                           0.357143            9.787235   \n",
       "56582                           0.222222            9.787235   \n",
       "5304                            2.388889            8.960468   \n",
       "\n",
       "       has_advanced_safety_features  age_gap  engine_power_density  \\\n",
       "7047                              0     47.0              0.075377   \n",
       "25110                             1     35.6              0.094403   \n",
       "58586                             1     35.8              0.091091   \n",
       "56582                             1     46.4              0.167448   \n",
       "5304                              0     57.2              0.075377   \n",
       "\n",
       "      safety_airbags_interaction  subscription_length_bucket  freq_segment  \n",
       "7047                           6                       Short      0.295938  \n",
       "25110                         22                       Short      0.313625  \n",
       "58586                         14                       Short      0.295938  \n",
       "56582                         96                       Short      0.238375  \n",
       "5304                           6                      Medium      0.295938  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed = fe.transform(X_train)\n",
    "print(X_transformed.shape)\n",
    "X_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OrdinalEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OrdinalEncoder.html\">?<span>Documentation for OrdinalEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "categorical_cols = [\n",
    "    col\n",
    "    for col in X_transformed.columns\n",
    "    if (\n",
    "        X_transformed[col].dtype == \"object\"\n",
    "        or pd.api.types.is_categorical_dtype(X_transformed[col])\n",
    "    )\n",
    "    and col != 'claim_status'\n",
    "]\n",
    "\n",
    "# Prepare encoder\n",
    "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "\n",
    "# Fit only on train set\n",
    "df_train_cats = X_transformed[categorical_cols].astype(str)\n",
    "encoder.fit(df_train_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed[categorical_cols] = encoder.transform(df_train_cats)\n",
    "\n",
    "X_transformed[\"claim_status\"] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules.xgb_tune import XGBoostTuner\n",
    "\n",
    "\n",
    "llm_tuner = XGBoostTuner(X_transformed, 'claim_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric Explanation: The target variable 'claim_status' is highly imbalanced (only ~6.5% positive class). You are primarily interested in PPV (Positive Predictive Value), also known as precision. For model selection, the most appropriate built-in scikit-learn metric is 'precision', which directly optimizes for the quantity you care about. This ensures that hyperparameter tuning selects configurations yielding the highest likelihood that predicted positives are indeed true positives, crucial in imbalanced/binary insurance claim contexts.\n",
      "Metric: precision\n",
      "Initial Search Space: Given this insurance claims dataset, there are several key considerations for hyperparameter search space setup:\n",
      "\n",
      "1. **Class Imbalance:** The target ('claim_status') has a pronounced imbalance (~6.5% positive). This justifies a wide, careful exploration of 'scale_pos_weight'. The optimal value is typically set to (# negative / # positive) or a range around it.\n",
      "   - Here: 14961 / 1039 ≈ 14.4\n",
      "   - We'll use loguniform(1, 30) to capture a reasonable range for imbalanced tuning.\n",
      "\n",
      "2. **Model Complexity (Over/Underfitting):**\n",
      "   - 'max_depth' controls model complexity; typical values range [3, 10] — deep enough for interaction, shallow enough to avoid heavy overfit on tabular data with ~50 columns.\n",
      "   - 'min_child_weight': use loguniform(1e-2, 10) — gives the option of very strict or lenient splitting.\n",
      "   - 'gamma': affects node splits; start with loguniform(1e-8, 10), covering very minimal to large required gain.\n",
      "\n",
      "3. **Regularization & Shrinkage:**\n",
      "   - 'reg_alpha' (L1) and 'reg_lambda' (L2): both loguniform(1e-5, 10), as regularization can be crucial to fight overfit with possible correlated features.\n",
      "   - 'learning_rate': loguniform(0.01, 0.3) — lower is slower/safer, but too low will need more boosting rounds.\n",
      "\n",
      "4. **Ensemble Size:**\n",
      "   - 'n_estimators': randint(100, 1200) — covers both quick/simple models and larger models.\n",
      "\n",
      "5. **Sampling:**\n",
      "   - 'subsample', 'colsample_bytree', 'colsample_bylevel': uniform(0.5, 0.5) samples 0.5 to 1.0, promoting both full and partial bagging/feature subsampling.\n",
      "\n",
      "For all loguniforms, use a lower bound > 0. For all stats, use scipy.stats (per instructions). This setup provides flexibility while bounding the search efficiently for this dataset size and risk of overfitting.\n",
      "\n",
      "Here's the code:\n",
      "\n",
      "--- Iteration 1/10 ---\n",
      "Top Config Summary:\n",
      "Configuration 1 (0.2667 test score): colsample_bylevel: 0.9057600738205926, colsample_bytree: 0.6547878023664807, gamma: 0.003505050426243573, learning_rate: 0.04186871081061139, max_depth: 7, min_child_weight: 0.03878401862139355, n_estimators: 630, reg_alpha: 0.015380119762549806, reg_lambda: 0.06299881925030629, scale_pos_weight: 8.101581744312588, subsample: 0.6531808417615129\n",
      "Configuration 2 (0.2500 test score): colsample_bylevel: 0.9057600738205926, colsample_bytree: 0.6547878023664807, gamma: 0.003505050426243573, learning_rate: 0.04186871081061139, max_depth: 7, min_child_weight: 0.03878401862139355, n_estimators: 630, reg_alpha: 0.015380119762549806, reg_lambda: 0.06299881925030629, scale_pos_weight: 8.101581744312588, subsample: 0.6531808417615129\n",
      "Configuration 3 (0.2400 test score): colsample_bylevel: 0.7872598403744007, colsample_bytree: 0.8959344137240566, gamma: 0.0005887430113395524, learning_rate: 0.17840979630301967, max_depth: 10, min_child_weight: 4.399749168949519, n_estimators: 473, reg_alpha: 0.12254058693626783, reg_lambda: 0.0012976395975277878, scale_pos_weight: 9.612746694988946, subsample: 0.749466107999063\n",
      "Configuration 4 (0.2000 test score): colsample_bylevel: 0.8021936650866095, colsample_bytree: 0.5843580785640197, gamma: 6.928002719076127e-06, learning_rate: 0.011942168247724242, max_depth: 9, min_child_weight: 6.00201326892396, n_estimators: 1025, reg_alpha: 1.036960862176692, reg_lambda: 0.002508633635873889, scale_pos_weight: 4.629841282825102, subsample: 0.9073403258432455\n",
      "Configuration 5 (0.2000 test score): colsample_bylevel: 0.5014510843546889, colsample_bytree: 0.7400356188492803, gamma: 0.1298875389662948, learning_rate: 0.13931694272374043, max_depth: 8, min_child_weight: 9.329460123881052, n_estimators: 1178, reg_alpha: 0.01839302630143982, reg_lambda: 0.005376986153930807, scale_pos_weight: 6.0839417371731646, subsample: 0.5523751299548051\n",
      "\n",
      "Last Run Best Score: 0.26666666666666666\n",
      "New best score: 0.26666666666666666\n",
      "\n",
      "Current top 1 configurations:\n",
      "  1. Score: 0.2667 (Iteration 1)\n",
      "Refine Search Space Prompt:\n",
      "\n",
      "Given your previously suggested search space, the obtained top configurations from the last run with their test scores:\n",
      "Configuration 1 (0.2667 test score): colsample_bylevel: 0.9057600738205926, colsample_bytree: 0.6547878023664807, gamma: 0.003505050426243573, learning_rate: 0.04186871081061139, max_depth: 7, min_child_weight: 0.03878401862139355, n_estimators: 630, reg_alpha: 0.015380119762549806, reg_lambda: 0.06299881925030629, scale_pos_weight: 8.101581744312588, subsample: 0.6531808417615129\n",
      "Configuration 2 (0.2500 test score): colsample_bylevel: 0.9057600738205926, colsample_bytree: 0.6547878023664807, gamma: 0.003505050426243573, learning_rate: 0.04186871081061139, max_depth: 7, min_child_weight: 0.03878401862139355, n_estimators: 630, reg_alpha: 0.015380119762549806, reg_lambda: 0.06299881925030629, scale_pos_weight: 8.101581744312588, subsample: 0.6531808417615129\n",
      "Configuration 3 (0.2400 test score): colsample_bylevel: 0.7872598403744007, colsample_bytree: 0.8959344137240566, gamma: 0.0005887430113395524, learning_rate: 0.17840979630301967, max_depth: 10, min_child_weight: 4.399749168949519, n_estimators: 473, reg_alpha: 0.12254058693626783, reg_lambda: 0.0012976395975277878, scale_pos_weight: 9.612746694988946, subsample: 0.749466107999063\n",
      "Configuration 4 (0.2000 test score): colsample_bylevel: 0.8021936650866095, colsample_bytree: 0.5843580785640197, gamma: 6.928002719076127e-06, learning_rate: 0.011942168247724242, max_depth: 9, min_child_weight: 6.00201326892396, n_estimators: 1025, reg_alpha: 1.036960862176692, reg_lambda: 0.002508633635873889, scale_pos_weight: 4.629841282825102, subsample: 0.9073403258432455\n",
      "Configuration 5 (0.2000 test score): colsample_bylevel: 0.5014510843546889, colsample_bytree: 0.7400356188492803, gamma: 0.1298875389662948, learning_rate: 0.13931694272374043, max_depth: 8, min_child_weight: 9.329460123881052, n_estimators: 1178, reg_alpha: 0.01839302630143982, reg_lambda: 0.005376986153930807, scale_pos_weight: 6.0839417371731646, subsample: 0.5523751299548051\n",
      "\n",
      "The best score from the last run was 0.26666666666666666, while the best score ever achieved in all previous runs is 0.26666666666666666\n",
      "\n",
      "Remember, tunable hyperparameters are: n_estimators, max_depth, min_child_samples, gamma, scale_pos_weight, learning_rate, subsample, colsample_bylevel, colsample_bytree, reg_alpha, and reg_lambda.\n",
      "\n",
      "Given the insights from the search history, your expertise in ML, and the need to further explore the search space, please suggest refinements for the search space in the next optimization round. Consider both narrowing and expanding the search space for hyperparameters where appropriate.\n",
      "\n",
      "For each recommendation, please:\n",
      "1. Explicitly tie back to any general best practices or patterns you are aware of regarding XGBoost tuning\n",
      "2. Then, relate to the insights from the search history and explain how they align or deviate from these practices or patterns.\n",
      "3. If suggesting an expansion of the search space, please provide a rationale for why a broader range could be beneficial.\n",
      "\n",
      "\n",
      "Briefly summarize your reasoning for the refinements and then present the adjusted configurations. Enclose your refined configurations between python code fences, and assign your configuration to a variable named search_space.\n",
      "\n",
      "\n",
      "\n",
      "Refined Search Space Reasoning:\n",
      "**1. General Best Practices:**\n",
      "- For imbalanced PPV-focused problems, tuning scale_pos_weight is crucial. XGBoost often benefits from deeper trees (max_depth 6-12) but risks overfitting. Extremely low min_child_weight and low gamma often produce bushier trees prone to overfit.\n",
      "- Precision (PPV) can be improved via higher regularization (reg_alpha, reg_lambda), pruning (min_child_weight, gamma), and more aggressive use of colsample/subsample.\n",
      "- For subsampling and colsampling, diversity is generally good unless all values congest near upper or lower bounds in previous results.\n",
      "\n",
      "**2. Insights from History:**\n",
      "- Search converged around moderate-to-deep trees (max_depth 7–10), low learning rates (0.01–0.18), min_child_weight values occasionally very low (<0.05), gamma near zero in most trials (right at the left edge), moderate n_estimators (473–1178).\n",
      "- Strong clustering of colsample_bylevel near the high end (>0.8) in high-performing runs—suggests the model benefits from wide feature sampling at level.\n",
      "- reg_lambda is very small in top configs—possible underregularization, consider expanding upward.\n",
      "- scale_pos_weight in top configs is 4.6–9.6, but the natural ratio suggests exploring higher values.\n",
      "\n",
      "**3. Refinements:**\n",
      "- Expand gamma and min_child_weight search upward: previous runs had many nearly-zero gammas/min_child_weight, try splitting with some higher values (0.01–20 for both).\n",
      "- Raise reg_lambda upper bound to 100 for stronger regularization exploration, and reg_alpha to 50.\n",
      "- Narrow learning_rate lower bound (results cluster above 0.01, never below), make upper bound a bit higher (log scale promotes exploration).\n",
      "- Expand scale_pos_weight (theoretically should try up to 20–25, given imbalance, as test values rarely go there, but natural ratio is ~14).\n",
      "- Keep max_depth as is, or allow up to 12 for deeper exploration but avoid massive depths.\n",
      "- For n_estimators, extend slight upward to allow more boosting rounds (1200–1600).\n",
      "- For colsample_bylevel, allow full range but lean 0.7–1.0, colsample_bytree 0.5–1.0 (highs worked previously, but test mids too).\n",
      "- For subsample, try full range 0.5–1.0.\n",
      "\n",
      "**Summary:**\n",
      "Broaden search for regularization and balancing (reg_lambda, reg_alpha, scale_pos_weight), let 'gamma' and 'min_child_weight' try larger values, open learning rate slightly, and broaden sampling/test more depth and estimators, while leaving space near well-performing clusters.\n",
      "\n",
      "\n",
      "--- Iteration 2/10 ---\n",
      "Top Config Summary:\n",
      "Configuration 1 (0.2500 test score): colsample_bylevel: 0.8427738449744723, colsample_bytree: 0.9522018774642388, gamma: 0.2782451515633441, learning_rate: 0.01697723221076909, max_depth: 11, min_child_weight: 14.753845752575565, n_estimators: 1360, reg_alpha: 0.0008866477176087025, reg_lambda: 18.160281786298448, scale_pos_weight: 23.50490710312581, subsample: 0.8536740941793342\n",
      "Configuration 2 (0.2500 test score): colsample_bylevel: 0.784317933040174, colsample_bytree: 0.8707410355257095, gamma: 0.19281859503836324, learning_rate: 0.3912890175110847, max_depth: 11, min_child_weight: 9.465314012415194, n_estimators: 1488, reg_alpha: 0.0009265148624854256, reg_lambda: 63.85850507394036, scale_pos_weight: 4.833218942762483, subsample: 0.8003685164459495\n",
      "Configuration 3 (0.2400 test score): colsample_bylevel: 0.7507162088679166, colsample_bytree: 0.608149005396176, gamma: 0.0003406108509116782, learning_rate: 0.3169155125136838, max_depth: 9, min_child_weight: 12.299930733681606, n_estimators: 1296, reg_alpha: 14.074484860016923, reg_lambda: 0.028316349519035517, scale_pos_weight: 19.67429292299279, subsample: 0.6009718029916671\n",
      "Configuration 4 (0.2250 test score): colsample_bylevel: 0.7336749105795551, colsample_bytree: 0.7097426553109333, gamma: 0.09978044148801284, learning_rate: 0.04199337273346665, max_depth: 8, min_child_weight: 7.731191004204091, n_estimators: 994, reg_alpha: 0.07430335442297957, reg_lambda: 0.010473647165391608, scale_pos_weight: 4.87234179421144, subsample: 0.51956107149462\n",
      "Configuration 5 (0.2200 test score): colsample_bylevel: 0.8955912533808903, colsample_bytree: 0.7615679171753932, gamma: 0.004324305097270475, learning_rate: 0.03205028138582622, max_depth: 6, min_child_weight: 2.3356898942130253, n_estimators: 761, reg_alpha: 0.0071636983719818624, reg_lambda: 14.406488341592542, scale_pos_weight: 12.77905863111212, subsample: 0.5081485875305158\n",
      "\n",
      "Last Run Best Score: 0.25\n",
      "No improvement. Consecutive runs without improvement: 1\n",
      "\n",
      "Current top 2 configurations:\n",
      "  1. Score: 0.2667 (Iteration 1)\n",
      "  2. Score: 0.2500 (Iteration 2)\n",
      "Refine Search Space Prompt:\n",
      "\n",
      "Given your previously suggested search space, the obtained top configurations from the last run with their test scores:\n",
      "Configuration 1 (0.2500 test score): colsample_bylevel: 0.8427738449744723, colsample_bytree: 0.9522018774642388, gamma: 0.2782451515633441, learning_rate: 0.01697723221076909, max_depth: 11, min_child_weight: 14.753845752575565, n_estimators: 1360, reg_alpha: 0.0008866477176087025, reg_lambda: 18.160281786298448, scale_pos_weight: 23.50490710312581, subsample: 0.8536740941793342\n",
      "Configuration 2 (0.2500 test score): colsample_bylevel: 0.784317933040174, colsample_bytree: 0.8707410355257095, gamma: 0.19281859503836324, learning_rate: 0.3912890175110847, max_depth: 11, min_child_weight: 9.465314012415194, n_estimators: 1488, reg_alpha: 0.0009265148624854256, reg_lambda: 63.85850507394036, scale_pos_weight: 4.833218942762483, subsample: 0.8003685164459495\n",
      "Configuration 3 (0.2400 test score): colsample_bylevel: 0.7507162088679166, colsample_bytree: 0.608149005396176, gamma: 0.0003406108509116782, learning_rate: 0.3169155125136838, max_depth: 9, min_child_weight: 12.299930733681606, n_estimators: 1296, reg_alpha: 14.074484860016923, reg_lambda: 0.028316349519035517, scale_pos_weight: 19.67429292299279, subsample: 0.6009718029916671\n",
      "Configuration 4 (0.2250 test score): colsample_bylevel: 0.7336749105795551, colsample_bytree: 0.7097426553109333, gamma: 0.09978044148801284, learning_rate: 0.04199337273346665, max_depth: 8, min_child_weight: 7.731191004204091, n_estimators: 994, reg_alpha: 0.07430335442297957, reg_lambda: 0.010473647165391608, scale_pos_weight: 4.87234179421144, subsample: 0.51956107149462\n",
      "Configuration 5 (0.2200 test score): colsample_bylevel: 0.8955912533808903, colsample_bytree: 0.7615679171753932, gamma: 0.004324305097270475, learning_rate: 0.03205028138582622, max_depth: 6, min_child_weight: 2.3356898942130253, n_estimators: 761, reg_alpha: 0.0071636983719818624, reg_lambda: 14.406488341592542, scale_pos_weight: 12.77905863111212, subsample: 0.5081485875305158\n",
      "\n",
      "Top configurations across ALL runs so far:\n",
      "Configuration 1 (0.2667 test score, from iteration 1): colsample_bylevel: 0.642684065287499, colsample_bytree: 0.8705675049493155, gamma: 0.6931755622735222, learning_rate: 0.030537009006022242, max_depth: 4, min_child_weight: 7.330431356819354, n_estimators: 162, reg_alpha: 0.00023800754162119547, reg_lambda: 0.1790501261127564, scale_pos_weight: 8.142995187170802, subsample: 0.8657589328408908\n",
      "Configuration 2 (0.2500 test score, from iteration 2): colsample_bylevel: 0.7472497691056, colsample_bytree: 0.5826055734351328, gamma: 8.191890212413906, learning_rate: 0.02968424379524942, max_depth: 10, min_child_weight: 0.42943316025406436, n_estimators: 769, reg_alpha: 0.4167157305138968, reg_lambda: 73.52141841201113, scale_pos_weight: 9.802707075709598, subsample: 0.7912635879477168\n",
      "\n",
      "The best score from the last run was 0.25, while the best score ever achieved in all previous runs is 0.26666666666666666\n",
      "\n",
      "Remember, tunable hyperparameters are: n_estimators, max_depth, min_child_samples, gamma, scale_pos_weight, learning_rate, subsample, colsample_bylevel, colsample_bytree, reg_alpha, and reg_lambda.\n",
      "\n",
      "Given the insights from the search history, your expertise in ML, and the need to further explore the search space, please suggest refinements for the search space in the next optimization round. Consider both narrowing and expanding the search space for hyperparameters where appropriate.\n",
      "\n",
      "For each recommendation, please:\n",
      "1. Explicitly tie back to any general best practices or patterns you are aware of regarding XGBoost tuning\n",
      "2. Then, relate to the insights from the search history and explain how they align or deviate from these practices or patterns.\n",
      "3. If suggesting an expansion of the search space, please provide a rationale for why a broader range could be beneficial.\n",
      "\n",
      "\n",
      "Briefly summarize your reasoning for the refinements and then present the adjusted configurations. Enclose your refined configurations between python code fences, and assign your configuration to a variable named search_space.\n",
      "\n",
      "\n",
      "\n",
      "Refined Search Space Reasoning:\n",
      "**Summary of Best Practices and Search Patterns:**\n",
      "- In XGBoost for heavily imbalanced binary classification (focus: precision), models often benefit from: regularization, careful class-weight tuning (scale_pos_weight), and pruning (using gamma/min_child_weight)\n",
      "- Too many estimators/too high depth may overfit to the majority negative class, hurting PPV. Smaller models with proper pruning are often superior unless many weak signals are distributed across features\n",
      "- Early best configs leveraged relatively lower n_estimators, lower max_depth, modest colsample_bylevel, moderate gamma (not tiny), low regularization, scale_pos_weight 8–10\n",
      "  - Latest runs: high min_child_weight, high max_depth, high n_estimators, high learning rates—generally suboptimal for precision in imbalanced settings, possibly causing underfitting or moving away from well-performing region\n",
      "  - Best configuration ever (“iteration 1”) suggests value in returning focus to lower tree complexity, lower n_estimators,\n",
      "    and lower min_child_weight and checking mid-range scale_pos_weight\n",
      "\n",
      "**Refinements (narrowing and re-centering search):**\n",
      "- Narrow n_estimators to 100–800: avoids overfitting/underfitting extremes, closer to performant prior region\n",
      "- Narrow max_depth to 3–8: deep enough for interaction, shrinks away from recent over-deep exploration\n",
      "- Focus min_child_weight and gamma on mid-low region but retain upside slack for discovery: (0.05–7) and (0.001–3)\n",
      "- Narrow learning_rate: best configs <0.05; set loguniform(0.01, 0.07) to force the optimizer into proven sweet spots\n",
      "- Re-center scale_pos_weight: 5–12 captures observed optimal and still includes the label imbalance prior\n",
      "- Narrow colsample_bytree and colsample_bylevel: best configs cluster in 0.65–0.9 and 0.6–0.9\n",
      "- Subsample similarly stays 0.6–0.9\n",
      "- reg_alpha, reg_lambda: pull back to 1e-4 to 10, as top configs almost always used mild regularization\n",
      "\n",
      "**Why Not Broaden Further?**\n",
      "At this stage, the optimizer has repeatedly achieved modest results by keeping the model small and regularized. Broadening, especially into deeper trees/more estimators, hasn’t improved test scores and likely encourages overfitting or underfitting, both of which harm PPV with imbalanced data. Instead, focus in on where performance has historically spiked is statistically smarter and computationally more efficient.\n",
      "\n",
      "Here is the refined configuration:\n",
      "\n",
      "--- Iteration 3/10 ---\n",
      "Top Config Summary:\n",
      "Configuration 1 (0.4000 test score): colsample_bylevel: 0.6779312524989076, colsample_bytree: 0.7599597018522273, gamma: 0.001007280424478658, learning_rate: 0.013454442478077736, max_depth: 8, min_child_weight: 0.0547986931348963, n_estimators: 623, reg_alpha: 0.006348506787140151, reg_lambda: 0.00033585047582956743, scale_pos_weight: 11.145136024742467, subsample: 0.7109381312440992\n",
      "Configuration 2 (0.4000 test score): colsample_bylevel: 0.7816779528784397, colsample_bytree: 0.6610318090082603, gamma: 0.0011766204915029752, learning_rate: 0.0123639967924529, max_depth: 7, min_child_weight: 0.381286771929437, n_estimators: 359, reg_alpha: 0.0018395188191961305, reg_lambda: 0.0002569945506904275, scale_pos_weight: 8.025417084419692, subsample: 0.8374066233491113\n",
      "Configuration 3 (0.4000 test score): colsample_bylevel: 0.7363445107260822, colsample_bytree: 0.8699832795234771, gamma: 0.7180169429023256, learning_rate: 0.019287036299077756, max_depth: 8, min_child_weight: 0.05286384798758806, n_estimators: 296, reg_alpha: 0.11448675248040391, reg_lambda: 0.00022246921506094782, scale_pos_weight: 5.810845849478305, subsample: 0.6181571251630464\n",
      "Configuration 4 (0.4000 test score): colsample_bylevel: 0.6642697844307754, colsample_bytree: 0.8044564418936331, gamma: 0.1805268484077251, learning_rate: 0.020957442137323697, max_depth: 7, min_child_weight: 0.058405714237354835, n_estimators: 172, reg_alpha: 0.24444794911416995, reg_lambda: 0.0047280512946710086, scale_pos_weight: 7.061427167845842, subsample: 0.6929981018613914\n",
      "Configuration 5 (0.4000 test score): colsample_bylevel: 0.7069172661353617, colsample_bytree: 0.8498504000832676, gamma: 0.03240529957308012, learning_rate: 0.029670905582606218, max_depth: 7, min_child_weight: 0.13210624678073965, n_estimators: 170, reg_alpha: 0.0683725801252713, reg_lambda: 0.07493699844992846, scale_pos_weight: 5.853367225302948, subsample: 0.7812780069418084\n",
      "\n",
      "Last Run Best Score: 0.4\n",
      "New best score: 0.4\n",
      "\n",
      "Current top 3 configurations:\n",
      "  1. Score: 0.4000 (Iteration 3)\n",
      "  2. Score: 0.2667 (Iteration 1)\n",
      "  3. Score: 0.2500 (Iteration 2)\n",
      "Refine Search Space Prompt:\n",
      "\n",
      "Given your previously suggested search space, the obtained top configurations from the last run with their test scores:\n",
      "Configuration 1 (0.4000 test score): colsample_bylevel: 0.6779312524989076, colsample_bytree: 0.7599597018522273, gamma: 0.001007280424478658, learning_rate: 0.013454442478077736, max_depth: 8, min_child_weight: 0.0547986931348963, n_estimators: 623, reg_alpha: 0.006348506787140151, reg_lambda: 0.00033585047582956743, scale_pos_weight: 11.145136024742467, subsample: 0.7109381312440992\n",
      "Configuration 2 (0.4000 test score): colsample_bylevel: 0.7816779528784397, colsample_bytree: 0.6610318090082603, gamma: 0.0011766204915029752, learning_rate: 0.0123639967924529, max_depth: 7, min_child_weight: 0.381286771929437, n_estimators: 359, reg_alpha: 0.0018395188191961305, reg_lambda: 0.0002569945506904275, scale_pos_weight: 8.025417084419692, subsample: 0.8374066233491113\n",
      "Configuration 3 (0.4000 test score): colsample_bylevel: 0.7363445107260822, colsample_bytree: 0.8699832795234771, gamma: 0.7180169429023256, learning_rate: 0.019287036299077756, max_depth: 8, min_child_weight: 0.05286384798758806, n_estimators: 296, reg_alpha: 0.11448675248040391, reg_lambda: 0.00022246921506094782, scale_pos_weight: 5.810845849478305, subsample: 0.6181571251630464\n",
      "Configuration 4 (0.4000 test score): colsample_bylevel: 0.6642697844307754, colsample_bytree: 0.8044564418936331, gamma: 0.1805268484077251, learning_rate: 0.020957442137323697, max_depth: 7, min_child_weight: 0.058405714237354835, n_estimators: 172, reg_alpha: 0.24444794911416995, reg_lambda: 0.0047280512946710086, scale_pos_weight: 7.061427167845842, subsample: 0.6929981018613914\n",
      "Configuration 5 (0.4000 test score): colsample_bylevel: 0.7069172661353617, colsample_bytree: 0.8498504000832676, gamma: 0.03240529957308012, learning_rate: 0.029670905582606218, max_depth: 7, min_child_weight: 0.13210624678073965, n_estimators: 170, reg_alpha: 0.0683725801252713, reg_lambda: 0.07493699844992846, scale_pos_weight: 5.853367225302948, subsample: 0.7812780069418084\n",
      "\n",
      "Top configurations across ALL runs so far:\n",
      "Configuration 1 (0.4000 test score, from iteration 3): colsample_bylevel: 0.7363445107260822, colsample_bytree: 0.8699832795234771, gamma: 0.7180169429023256, learning_rate: 0.019287036299077756, max_depth: 8, min_child_weight: 0.05286384798758806, n_estimators: 296, reg_alpha: 0.11448675248040391, reg_lambda: 0.00022246921506094782, scale_pos_weight: 5.810845849478305, subsample: 0.6181571251630464\n",
      "Configuration 2 (0.2667 test score, from iteration 1): colsample_bylevel: 0.642684065287499, colsample_bytree: 0.8705675049493155, gamma: 0.6931755622735222, learning_rate: 0.030537009006022242, max_depth: 4, min_child_weight: 7.330431356819354, n_estimators: 162, reg_alpha: 0.00023800754162119547, reg_lambda: 0.1790501261127564, scale_pos_weight: 8.142995187170802, subsample: 0.8657589328408908\n",
      "Configuration 3 (0.2500 test score, from iteration 2): colsample_bylevel: 0.7472497691056, colsample_bytree: 0.5826055734351328, gamma: 8.191890212413906, learning_rate: 0.02968424379524942, max_depth: 10, min_child_weight: 0.42943316025406436, n_estimators: 769, reg_alpha: 0.4167157305138968, reg_lambda: 73.52141841201113, scale_pos_weight: 9.802707075709598, subsample: 0.7912635879477168\n",
      "\n",
      "The best score from the last run was 0.4, while the best score ever achieved in all previous runs is 0.4\n",
      "\n",
      "Remember, tunable hyperparameters are: n_estimators, max_depth, min_child_samples, gamma, scale_pos_weight, learning_rate, subsample, colsample_bylevel, colsample_bytree, reg_alpha, and reg_lambda.\n",
      "\n",
      "Given the insights from the search history, your expertise in ML, and the need to further explore the search space, please suggest refinements for the search space in the next optimization round. Consider both narrowing and expanding the search space for hyperparameters where appropriate.\n",
      "\n",
      "For each recommendation, please:\n",
      "1. Explicitly tie back to any general best practices or patterns you are aware of regarding XGBoost tuning\n",
      "2. Then, relate to the insights from the search history and explain how they align or deviate from these practices or patterns.\n",
      "3. If suggesting an expansion of the search space, please provide a rationale for why a broader range could be beneficial.\n",
      "\n",
      "\n",
      "Briefly summarize your reasoning for the refinements and then present the adjusted configurations. Enclose your refined configurations between python code fences, and assign your configuration to a variable named search_space.\n",
      "\n",
      "\n",
      "\n",
      "Refined Search Space Reasoning:\n",
      "1. Best Practices and Patterns:\n",
      "- With highly imbalanced binary data (and precision as the goal), high max_depth and many boosting rounds usually promote overfitting. Instead, optimal models often use modest tree depth, mild number of trees, low to moderate learning rates, and exploit regularization and sampling.\n",
      "- For PPV (Precision) specifically, tuning min_child_weight and gamma for \"pruning\" can be important; very low values can risk overfitting, but a bit of slack is needed for interaction. reg_alpha/reg_lambda fine-tune regularization, but extremely low values may underuse these controls.\n",
      "- scale_pos_weight set near the imbalance ratio is standard, but search shows the best recent configs lean toward 6–12.\n",
      "\n",
      "2. Recent Search Insights:\n",
      "- All top runs in the last round have high test-score clusters, with: low learning rates (~0.012–0.03), max_depth 7–8, n_estimators 170–623, min_child_weight < 0.4 (often very low), gamma between 0.001 and 0.7 (suggesting a benefit from wider gamma region). reg_alpha/reg_lambda are very low, though small increases seem non-harmful.\n",
      "- colsample_bytree/bylevel/subsample cluster ~0.65–0.87, suggesting the importance of sampling diversity, but rarely hitting the edges.\n",
      "- None tested extremely high min_child_weight or deep trees in last high-performing configurations; seems unnecessary to open that up.\n",
      "\n",
      "3. Recommendations & Refinement:\n",
      "- Narrow all sampling ratios to the window in which most 0.4-scoring configs occurred (0.65–0.90).\n",
      "- Contract learning_rate loguniform to (0.012, 0.04), focusing at the zone working best.\n",
      "- Narrow max_depth to (6, 9), min_child_weight to (0.05, 1.2): maintain some ability to regularize with child weight, but keep matching low cluster.\n",
      "- n_estimators from 150–700: nearly all best runs fit within, avoids extremes.\n",
      "- gamma: loguniform(0.001, 1) – wider than the tightest cluster, allows further pruning, but not so extreme as earlier runs.\n",
      "- reg_alpha/reg_lambda: high-performing configs are very low, but nudge upper bound to 1 for enough regularization.\n",
      "- scale_pos_weight: all latest best configs 5.8–11, so uniform(5.5, 6.5), covering the sweet spot as well as imbalance ratio. We can consider exploring still a bit wider in future if plateau.\n",
      "\n",
      "4. Why Not Expand? Because ever-increasing tree complexity, estimator count, or regularization did not help PPV on this data as seen in prior runs. Instead, focus finely around high-performing region and maximize search efficiency for local optima.\n",
      "\n",
      "Here is the refined search space:\n",
      "\n",
      "--- Iteration 4/10 ---\n",
      "Top Config Summary:\n",
      "Configuration 1 (0.2167 test score): colsample_bylevel: 0.7819401533232064, colsample_bytree: 0.7456806780332187, gamma: 0.22336738931797995, learning_rate: 0.012969965710744618, max_depth: 6, min_child_weight: 0.20411898457666883, n_estimators: 151, reg_alpha: 0.9604777696298764, reg_lambda: 0.00011102804499302985, scale_pos_weight: 6.142602551599214, subsample: 0.8279851847314226\n",
      "Configuration 2 (0.2000 test score): colsample_bylevel: 0.6753409624134197, colsample_bytree: 0.7859539775985976, gamma: 0.06899175004157103, learning_rate: 0.020643800938580908, max_depth: 8, min_child_weight: 0.1226727776444361, n_estimators: 615, reg_alpha: 0.032284755541032925, reg_lambda: 0.0017209024526870448, scale_pos_weight: 7.975851158574329, subsample: 0.6869189656166113\n",
      "Configuration 3 (0.2000 test score): colsample_bylevel: 0.737762585936279, colsample_bytree: 0.866757339017436, gamma: 0.020692588258387632, learning_rate: 0.013174215430979545, max_depth: 8, min_child_weight: 0.24453596626521548, n_estimators: 289, reg_alpha: 0.0009875733065378889, reg_lambda: 0.0038264347864766816, scale_pos_weight: 8.685636489723628, subsample: 0.8846685456827619\n",
      "Configuration 4 (0.2000 test score): colsample_bylevel: 0.8497388573243221, colsample_bytree: 0.675230830009972, gamma: 0.9010762738805979, learning_rate: 0.039320438275825695, max_depth: 7, min_child_weight: 0.3206899663137568, n_estimators: 660, reg_alpha: 0.30907371842391157, reg_lambda: 0.09360558240635576, scale_pos_weight: 11.361836647408206, subsample: 0.7497711703866136\n",
      "Configuration 5 (0.2000 test score): colsample_bylevel: 0.7299537306050956, colsample_bytree: 0.6749733282272743, gamma: 0.9789350847756375, learning_rate: 0.032484440631011746, max_depth: 7, min_child_weight: 0.18123824983368317, n_estimators: 518, reg_alpha: 0.001068098874892495, reg_lambda: 0.1513875173168228, scale_pos_weight: 7.886575333859348, subsample: 0.7547326702132268\n",
      "\n",
      "Last Run Best Score: 0.21666666666666665\n",
      "No improvement. Consecutive runs without improvement: 1\n",
      "\n",
      "Current top 4 configurations:\n",
      "  1. Score: 0.4000 (Iteration 3)\n",
      "  2. Score: 0.2667 (Iteration 1)\n",
      "  3. Score: 0.2500 (Iteration 2)\n",
      "  4. Score: 0.2167 (Iteration 4)\n",
      "Refine Search Space Prompt:\n",
      "\n",
      "Given your previously suggested search space, the obtained top configurations from the last run with their test scores:\n",
      "Configuration 1 (0.2167 test score): colsample_bylevel: 0.7819401533232064, colsample_bytree: 0.7456806780332187, gamma: 0.22336738931797995, learning_rate: 0.012969965710744618, max_depth: 6, min_child_weight: 0.20411898457666883, n_estimators: 151, reg_alpha: 0.9604777696298764, reg_lambda: 0.00011102804499302985, scale_pos_weight: 6.142602551599214, subsample: 0.8279851847314226\n",
      "Configuration 2 (0.2000 test score): colsample_bylevel: 0.6753409624134197, colsample_bytree: 0.7859539775985976, gamma: 0.06899175004157103, learning_rate: 0.020643800938580908, max_depth: 8, min_child_weight: 0.1226727776444361, n_estimators: 615, reg_alpha: 0.032284755541032925, reg_lambda: 0.0017209024526870448, scale_pos_weight: 7.975851158574329, subsample: 0.6869189656166113\n",
      "Configuration 3 (0.2000 test score): colsample_bylevel: 0.737762585936279, colsample_bytree: 0.866757339017436, gamma: 0.020692588258387632, learning_rate: 0.013174215430979545, max_depth: 8, min_child_weight: 0.24453596626521548, n_estimators: 289, reg_alpha: 0.0009875733065378889, reg_lambda: 0.0038264347864766816, scale_pos_weight: 8.685636489723628, subsample: 0.8846685456827619\n",
      "Configuration 4 (0.2000 test score): colsample_bylevel: 0.8497388573243221, colsample_bytree: 0.675230830009972, gamma: 0.9010762738805979, learning_rate: 0.039320438275825695, max_depth: 7, min_child_weight: 0.3206899663137568, n_estimators: 660, reg_alpha: 0.30907371842391157, reg_lambda: 0.09360558240635576, scale_pos_weight: 11.361836647408206, subsample: 0.7497711703866136\n",
      "Configuration 5 (0.2000 test score): colsample_bylevel: 0.7299537306050956, colsample_bytree: 0.6749733282272743, gamma: 0.9789350847756375, learning_rate: 0.032484440631011746, max_depth: 7, min_child_weight: 0.18123824983368317, n_estimators: 518, reg_alpha: 0.001068098874892495, reg_lambda: 0.1513875173168228, scale_pos_weight: 7.886575333859348, subsample: 0.7547326702132268\n",
      "\n",
      "Top configurations across ALL runs so far:\n",
      "Configuration 1 (0.4000 test score, from iteration 3): colsample_bylevel: 0.7363445107260822, colsample_bytree: 0.8699832795234771, gamma: 0.7180169429023256, learning_rate: 0.019287036299077756, max_depth: 8, min_child_weight: 0.05286384798758806, n_estimators: 296, reg_alpha: 0.11448675248040391, reg_lambda: 0.00022246921506094782, scale_pos_weight: 5.810845849478305, subsample: 0.6181571251630464\n",
      "Configuration 2 (0.2667 test score, from iteration 1): colsample_bylevel: 0.642684065287499, colsample_bytree: 0.8705675049493155, gamma: 0.6931755622735222, learning_rate: 0.030537009006022242, max_depth: 4, min_child_weight: 7.330431356819354, n_estimators: 162, reg_alpha: 0.00023800754162119547, reg_lambda: 0.1790501261127564, scale_pos_weight: 8.142995187170802, subsample: 0.8657589328408908\n",
      "Configuration 3 (0.2500 test score, from iteration 2): colsample_bylevel: 0.7472497691056, colsample_bytree: 0.5826055734351328, gamma: 8.191890212413906, learning_rate: 0.02968424379524942, max_depth: 10, min_child_weight: 0.42943316025406436, n_estimators: 769, reg_alpha: 0.4167157305138968, reg_lambda: 73.52141841201113, scale_pos_weight: 9.802707075709598, subsample: 0.7912635879477168\n",
      "Configuration 4 (0.2167 test score, from iteration 4): colsample_bylevel: 0.6972338517711929, colsample_bytree: 0.8365506923102773, gamma: 0.0015732231847227643, learning_rate: 0.03346631383448761, max_depth: 6, min_child_weight: 0.18969208283099037, n_estimators: 168, reg_alpha: 0.0003538245911590417, reg_lambda: 0.04347874144550115, scale_pos_weight: 6.362644180650792, subsample: 0.7051669470504931\n",
      "\n",
      "The best score from the last run was 0.21666666666666665, while the best score ever achieved in all previous runs is 0.4\n",
      "\n",
      "Remember, tunable hyperparameters are: n_estimators, max_depth, min_child_samples, gamma, scale_pos_weight, learning_rate, subsample, colsample_bylevel, colsample_bytree, reg_alpha, and reg_lambda.\n",
      "\n",
      "Given the insights from the search history, your expertise in ML, and the need to further explore the search space, please suggest refinements for the search space in the next optimization round. Consider both narrowing and expanding the search space for hyperparameters where appropriate.\n",
      "\n",
      "For each recommendation, please:\n",
      "1. Explicitly tie back to any general best practices or patterns you are aware of regarding XGBoost tuning\n",
      "2. Then, relate to the insights from the search history and explain how they align or deviate from these practices or patterns.\n",
      "3. If suggesting an expansion of the search space, please provide a rationale for why a broader range could be beneficial.\n",
      "\n",
      "\n",
      "Briefly summarize your reasoning for the refinements and then present the adjusted configurations. Enclose your refined configurations between python code fences, and assign your configuration to a variable named search_space.\n",
      "\n",
      "\n",
      "\n",
      "Refined Search Space Reasoning:\n",
      "1. Best Practices and Patterns:\n",
      "- In XGBoost for imbalanced, binary, PPV-optimized tasks, the most effective models usually find a sweet spot with tree depth, boosting rounds, and regularization—not too deep, not too shallow, careful use of sampling and class weighting. Sometimes, models can be too constrained, missing useful complexity.\n",
      "\n",
      "2. Insights from Recent Search History:\n",
      "- Current top run (0.4 score) uses max_depth=8, n_estimators=296, learning_rate~0.0193, min_child_weight~0.05, gamma~0.7, scale_pos_weight~5.8, and modest regularization. Multiple 0.4 configs have very low min_child_weight, low gamma, but still within range, and moderate-to-low regularization.\n",
      "- The last run’s bests (max score 0.2167) cluster in similar hyperparameter spaces with n_estimators at edges (near lower or upper), reg_alpha higher than previous, little pattern in gamma/min_child_weight apart from preference for low values. No high-PPV configs used extremely high regularization or tree complexity. Learning_rate stayed low and tight. \n",
      "\n",
      "However, subsequent runs did not reproduce high scores, suggesting possible over-narrowing or effect of randomness/mild overfitting in previous top configs. We may be missing moderate min_child_weight or gamma, or need a broader sweep on scale_pos_weight.\n",
      "\n",
      "3. Recommendations:\n",
      "- Slightly widen learning_rate to (0.01, 0.05): accommodate possibly slightly faster learning.\n",
      "- Extend n_estimators range 150–850, as top config was near lower bound, others near upper.\n",
      "- Broaden min_child_weight loguniform to (0.03, 2): allow both the lowest cluster (still favored) but more moderate splits just in case.\n",
      "- Broaden gamma loguniform (0.001, 2): capture not only very low but also small-to-moderate pruning.\n",
      "- Keep max_depth (6, 10). Retain mid-high sampling (0.65–0.9) as consistent winners.\n",
      "- Slightly widen scale_pos_weight to (5, 12): there is no evidence too high is good, but best all fell in this space.\n",
      "- Pull reg_alpha and reg_lambda (1e-4, 2): continue allowing a bit more regularization as in recent configs.\n",
      "- Rationale for this tuning: Since best performance was not reproducible with very tightly focused search, the data may benefit from a hybrid local/global exploration, avoiding premature convergence.\n",
      "\n",
      "Summary: Slightly expand the search space for min_child_weight, gamma, n_estimators, learning_rate, and scale_pos_weight around the high-performing cluster, while keeping all other choices in the proven effective ranges to balance local exploitation and mild exploration.\n",
      "\n",
      "\n",
      "--- Iteration 5/10 ---\n",
      "Top Config Summary:\n",
      "Configuration 1 (0.6000 test score): colsample_bylevel: 0.7427950049606705, colsample_bytree: 0.8146839166124433, gamma: 1.1835695763144383, learning_rate: 0.020438028378312833, max_depth: 9, min_child_weight: 0.11745182520058824, n_estimators: 503, reg_alpha: 0.0004959261013297433, reg_lambda: 0.060532382707423796, scale_pos_weight: 9.78287604497128, subsample: 0.8865477536562119\n",
      "Configuration 2 (0.5000 test score): colsample_bylevel: 0.7401724792385335, colsample_bytree: 0.8592450553181544, gamma: 1.014705712558558, learning_rate: 0.017026780215199943, max_depth: 7, min_child_weight: 0.03030597566968193, n_estimators: 159, reg_alpha: 0.053656792940550896, reg_lambda: 0.0023438100857759267, scale_pos_weight: 10.238637592118524, subsample: 0.8759255886187081\n",
      "Configuration 3 (0.4000 test score): colsample_bylevel: 0.7311588603314787, colsample_bytree: 0.7809517491489458, gamma: 0.44636746750189504, learning_rate: 0.014372052752083865, max_depth: 6, min_child_weight: 0.05948101979082752, n_estimators: 453, reg_alpha: 0.05410311149345672, reg_lambda: 0.0007437201632199273, scale_pos_weight: 7.465182409244403, subsample: 0.7025821465651266\n",
      "Configuration 4 (0.4000 test score): colsample_bylevel: 0.761478021541793, colsample_bytree: 0.7600243760549924, gamma: 0.5103889419265638, learning_rate: 0.03192604513284882, max_depth: 7, min_child_weight: 0.05927040617777147, n_estimators: 297, reg_alpha: 0.0012099799723604076, reg_lambda: 0.004344201717227432, scale_pos_weight: 5.932036228263507, subsample: 0.8160056947826001\n",
      "Configuration 5 (0.4000 test score): colsample_bylevel: 0.7807620937719941, colsample_bytree: 0.840113313042077, gamma: 0.5767631468467427, learning_rate: 0.021905483464968078, max_depth: 9, min_child_weight: 0.1525831815607763, n_estimators: 684, reg_alpha: 0.10121638804571265, reg_lambda: 0.08386009461304765, scale_pos_weight: 9.417790409938473, subsample: 0.8945015890188758\n",
      "\n",
      "Last Run Best Score: 0.6\n",
      "New best score: 0.6\n",
      "\n",
      "Current top 5 configurations:\n",
      "  1. Score: 0.6000 (Iteration 5)\n",
      "  2. Score: 0.4000 (Iteration 3)\n",
      "  3. Score: 0.2667 (Iteration 1)\n",
      "  4. Score: 0.2500 (Iteration 2)\n",
      "  5. Score: 0.2167 (Iteration 4)\n",
      "Refine Search Space Prompt:\n",
      "\n",
      "Given your previously suggested search space, the obtained top configurations from the last run with their test scores:\n",
      "Configuration 1 (0.6000 test score): colsample_bylevel: 0.7427950049606705, colsample_bytree: 0.8146839166124433, gamma: 1.1835695763144383, learning_rate: 0.020438028378312833, max_depth: 9, min_child_weight: 0.11745182520058824, n_estimators: 503, reg_alpha: 0.0004959261013297433, reg_lambda: 0.060532382707423796, scale_pos_weight: 9.78287604497128, subsample: 0.8865477536562119\n",
      "Configuration 2 (0.5000 test score): colsample_bylevel: 0.7401724792385335, colsample_bytree: 0.8592450553181544, gamma: 1.014705712558558, learning_rate: 0.017026780215199943, max_depth: 7, min_child_weight: 0.03030597566968193, n_estimators: 159, reg_alpha: 0.053656792940550896, reg_lambda: 0.0023438100857759267, scale_pos_weight: 10.238637592118524, subsample: 0.8759255886187081\n",
      "Configuration 3 (0.4000 test score): colsample_bylevel: 0.7311588603314787, colsample_bytree: 0.7809517491489458, gamma: 0.44636746750189504, learning_rate: 0.014372052752083865, max_depth: 6, min_child_weight: 0.05948101979082752, n_estimators: 453, reg_alpha: 0.05410311149345672, reg_lambda: 0.0007437201632199273, scale_pos_weight: 7.465182409244403, subsample: 0.7025821465651266\n",
      "Configuration 4 (0.4000 test score): colsample_bylevel: 0.761478021541793, colsample_bytree: 0.7600243760549924, gamma: 0.5103889419265638, learning_rate: 0.03192604513284882, max_depth: 7, min_child_weight: 0.05927040617777147, n_estimators: 297, reg_alpha: 0.0012099799723604076, reg_lambda: 0.004344201717227432, scale_pos_weight: 5.932036228263507, subsample: 0.8160056947826001\n",
      "Configuration 5 (0.4000 test score): colsample_bylevel: 0.7807620937719941, colsample_bytree: 0.840113313042077, gamma: 0.5767631468467427, learning_rate: 0.021905483464968078, max_depth: 9, min_child_weight: 0.1525831815607763, n_estimators: 684, reg_alpha: 0.10121638804571265, reg_lambda: 0.08386009461304765, scale_pos_weight: 9.417790409938473, subsample: 0.8945015890188758\n",
      "\n",
      "Top configurations across ALL runs so far:\n",
      "Configuration 1 (0.6000 test score, from iteration 5): colsample_bylevel: 0.6819796804585989, colsample_bytree: 0.8769995435403075, gamma: 0.36267123343479407, learning_rate: 0.011181214516269689, max_depth: 9, min_child_weight: 0.16983181528269106, n_estimators: 216, reg_alpha: 1.390273909440899, reg_lambda: 0.6519317236818201, scale_pos_weight: 8.758423316352669, subsample: 0.7861149134412877\n",
      "Configuration 2 (0.4000 test score, from iteration 3): colsample_bylevel: 0.7363445107260822, colsample_bytree: 0.8699832795234771, gamma: 0.7180169429023256, learning_rate: 0.019287036299077756, max_depth: 8, min_child_weight: 0.05286384798758806, n_estimators: 296, reg_alpha: 0.11448675248040391, reg_lambda: 0.00022246921506094782, scale_pos_weight: 5.810845849478305, subsample: 0.6181571251630464\n",
      "Configuration 3 (0.2667 test score, from iteration 1): colsample_bylevel: 0.642684065287499, colsample_bytree: 0.8705675049493155, gamma: 0.6931755622735222, learning_rate: 0.030537009006022242, max_depth: 4, min_child_weight: 7.330431356819354, n_estimators: 162, reg_alpha: 0.00023800754162119547, reg_lambda: 0.1790501261127564, scale_pos_weight: 8.142995187170802, subsample: 0.8657589328408908\n",
      "Configuration 4 (0.2500 test score, from iteration 2): colsample_bylevel: 0.7472497691056, colsample_bytree: 0.5826055734351328, gamma: 8.191890212413906, learning_rate: 0.02968424379524942, max_depth: 10, min_child_weight: 0.42943316025406436, n_estimators: 769, reg_alpha: 0.4167157305138968, reg_lambda: 73.52141841201113, scale_pos_weight: 9.802707075709598, subsample: 0.7912635879477168\n",
      "Configuration 5 (0.2167 test score, from iteration 4): colsample_bylevel: 0.6972338517711929, colsample_bytree: 0.8365506923102773, gamma: 0.0015732231847227643, learning_rate: 0.03346631383448761, max_depth: 6, min_child_weight: 0.18969208283099037, n_estimators: 168, reg_alpha: 0.0003538245911590417, reg_lambda: 0.04347874144550115, scale_pos_weight: 6.362644180650792, subsample: 0.7051669470504931\n",
      "\n",
      "The best score from the last run was 0.6, while the best score ever achieved in all previous runs is 0.6\n",
      "\n",
      "Remember, tunable hyperparameters are: n_estimators, max_depth, min_child_samples, gamma, scale_pos_weight, learning_rate, subsample, colsample_bylevel, colsample_bytree, reg_alpha, and reg_lambda.\n",
      "\n",
      "Given the insights from the search history, your expertise in ML, and the need to further explore the search space, please suggest refinements for the search space in the next optimization round. Consider both narrowing and expanding the search space for hyperparameters where appropriate.\n",
      "\n",
      "For each recommendation, please:\n",
      "1. Explicitly tie back to any general best practices or patterns you are aware of regarding XGBoost tuning\n",
      "2. Then, relate to the insights from the search history and explain how they align or deviate from these practices or patterns.\n",
      "3. If suggesting an expansion of the search space, please provide a rationale for why a broader range could be beneficial.\n",
      "\n",
      "\n",
      "Briefly summarize your reasoning for the refinements and then present the adjusted configurations. Enclose your refined configurations between python code fences, and assign your configuration to a variable named search_space.\n",
      "\n",
      "\n",
      "\n",
      "Refined Search Space Reasoning:\n",
      "1. Best Practices:\n",
      "- When a new best score is reached (especially a large jump, 0.4→0.6), best practice is to focus local search near this new optimum, but also allow some moderate exploratory expansion. XGBoost for imbalanced, PPV-driven problems generally favors moderately deep trees (max_depth 6–10), low learning rates, and careful use of class weighting and pruning.\n",
      "\n",
      "2. Search History Insights:\n",
      "- Recent top configs: low min_child_weight (~0.12–0.17), max_depth of 9, scale_pos_weight ~8.7–10.2, gamma of 0.36–1.18, learning rate very low (0.01–0.03), n_estimators spread mid-range.\n",
      "- The 0.6 config used modest reg_alpha/reg_lambda, reconfirming that very high regularization is not beneficial for PPV in this data. colsample and subsample remain 0.78–0.88, so no need to expand.\n",
      "- The jump in score suggests a promising region, so further refinements should narrow/saturate search around these values, but allow more children at leaves (min_child_weight up to 0.4), and also explore slightly lower and higher gamma, as well as a touch wider learning rate and n_estimators window to check for consistent results and prevent luck/randomness overfitting.\n",
      "\n",
      "3. Changes:\n",
      "- n_estimators: tighten to (200, 700), as best configs are within and none at boundaries.\n",
      "- learning_rate: keep (0.011, 0.035), as best are here, but widen very slightly to check edge cases.\n",
      "- max_depth: (8, 11) for a shallow increase, given repeated use of 9 and sometimes 10.\n",
      "- min_child_weight: (0.05, 0.4) since all best are very low, but allow a bit higher for slight regularization.\n",
      "- gamma: allow (0.2, 1.7), as top scores came from 0.36–1.18, and allow a bit more on both sides to capture possible patterns.\n",
      "- scale_pos_weight: uniform(8, 4), i.e., 8–12 (almost all best are 8.7–10.2).\n",
      "- subsample/colsample_: narrow to (0.77–0.92), as all top configs are inside this window.\n",
      "- reg_alpha and reg_lambda: best configs at 0.0004–0.1, so keep (1e-5, 0.15).\n",
      "\n",
      "Summary: Saturate search near best-found region, with a slightly wider window for gamma and min_child_weight for local exploration, as well as a slight nudge up in depth and n_estimators. If gains plateau or degenerate, consider re-broadening or multi-modal exploration, but now focus on local refinement.\n",
      "\n",
      "--- Iteration 6/10 ---\n",
      "Top Config Summary:\n",
      "Configuration 1 (0.2800 test score): colsample_bylevel: 0.8719385115865879, colsample_bytree: 0.821107803429561, gamma: 0.42930776678684074, learning_rate: 0.02696766033727369, max_depth: 10, min_child_weight: 0.16583168804374668, n_estimators: 409, reg_alpha: 0.005799002124596856, reg_lambda: 0.05042742930566304, scale_pos_weight: 9.86482230475275, subsample: 0.777044373405066\n",
      "Configuration 2 (0.2750 test score): colsample_bylevel: 0.9153984440191909, colsample_bytree: 0.9088957078001273, gamma: 0.7509749399849712, learning_rate: 0.023427525709111195, max_depth: 11, min_child_weight: 0.3545399795568791, n_estimators: 646, reg_alpha: 0.0008460613264258953, reg_lambda: 1.8534589872330325e-05, scale_pos_weight: 8.906339505182503, subsample: 0.8200438924773005\n",
      "Configuration 3 (0.2750 test score): colsample_bylevel: 0.8995247210911426, colsample_bytree: 0.7740321454598763, gamma: 1.6983384921432385, learning_rate: 0.024926861699680107, max_depth: 11, min_child_weight: 0.07577854775561291, n_estimators: 318, reg_alpha: 0.0004965931296000774, reg_lambda: 0.043251880566532, scale_pos_weight: 8.65241363370017, subsample: 0.8642346481268052\n",
      "Configuration 4 (0.2667 test score): colsample_bylevel: 0.9169110443293246, colsample_bytree: 0.7998038754960295, gamma: 0.3829025986856622, learning_rate: 0.029841874591447805, max_depth: 10, min_child_weight: 0.16010339589365935, n_estimators: 699, reg_alpha: 0.010471065755558376, reg_lambda: 0.025481421153390582, scale_pos_weight: 8.508391987852248, subsample: 0.7832563384921605\n",
      "Configuration 5 (0.2500 test score): colsample_bylevel: 0.8723222217842436, colsample_bytree: 0.8028831077754298, gamma: 0.4338666699883288, learning_rate: 0.014178316715098806, max_depth: 11, min_child_weight: 0.30428458717326323, n_estimators: 514, reg_alpha: 2.032497340504844e-05, reg_lambda: 0.053632483981902984, scale_pos_weight: 11.47892543317153, subsample: 0.8077835002077979\n",
      "\n",
      "Last Run Best Score: 0.27999999999999997\n",
      "No improvement. Consecutive runs without improvement: 1\n",
      "\n",
      "Current top 5 configurations:\n",
      "  1. Score: 0.6000 (Iteration 5)\n",
      "  2. Score: 0.4000 (Iteration 3)\n",
      "  3. Score: 0.2800 (Iteration 6)\n",
      "  4. Score: 0.2667 (Iteration 1)\n",
      "  5. Score: 0.2500 (Iteration 2)\n",
      "Refine Search Space Prompt:\n",
      "\n",
      "Given your previously suggested search space, the obtained top configurations from the last run with their test scores:\n",
      "Configuration 1 (0.2800 test score): colsample_bylevel: 0.8719385115865879, colsample_bytree: 0.821107803429561, gamma: 0.42930776678684074, learning_rate: 0.02696766033727369, max_depth: 10, min_child_weight: 0.16583168804374668, n_estimators: 409, reg_alpha: 0.005799002124596856, reg_lambda: 0.05042742930566304, scale_pos_weight: 9.86482230475275, subsample: 0.777044373405066\n",
      "Configuration 2 (0.2750 test score): colsample_bylevel: 0.9153984440191909, colsample_bytree: 0.9088957078001273, gamma: 0.7509749399849712, learning_rate: 0.023427525709111195, max_depth: 11, min_child_weight: 0.3545399795568791, n_estimators: 646, reg_alpha: 0.0008460613264258953, reg_lambda: 1.8534589872330325e-05, scale_pos_weight: 8.906339505182503, subsample: 0.8200438924773005\n",
      "Configuration 3 (0.2750 test score): colsample_bylevel: 0.8995247210911426, colsample_bytree: 0.7740321454598763, gamma: 1.6983384921432385, learning_rate: 0.024926861699680107, max_depth: 11, min_child_weight: 0.07577854775561291, n_estimators: 318, reg_alpha: 0.0004965931296000774, reg_lambda: 0.043251880566532, scale_pos_weight: 8.65241363370017, subsample: 0.8642346481268052\n",
      "Configuration 4 (0.2667 test score): colsample_bylevel: 0.9169110443293246, colsample_bytree: 0.7998038754960295, gamma: 0.3829025986856622, learning_rate: 0.029841874591447805, max_depth: 10, min_child_weight: 0.16010339589365935, n_estimators: 699, reg_alpha: 0.010471065755558376, reg_lambda: 0.025481421153390582, scale_pos_weight: 8.508391987852248, subsample: 0.7832563384921605\n",
      "Configuration 5 (0.2500 test score): colsample_bylevel: 0.8723222217842436, colsample_bytree: 0.8028831077754298, gamma: 0.4338666699883288, learning_rate: 0.014178316715098806, max_depth: 11, min_child_weight: 0.30428458717326323, n_estimators: 514, reg_alpha: 2.032497340504844e-05, reg_lambda: 0.053632483981902984, scale_pos_weight: 11.47892543317153, subsample: 0.8077835002077979\n",
      "\n",
      "Top configurations across ALL runs so far:\n",
      "Configuration 1 (0.6000 test score, from iteration 5): colsample_bylevel: 0.6819796804585989, colsample_bytree: 0.8769995435403075, gamma: 0.36267123343479407, learning_rate: 0.011181214516269689, max_depth: 9, min_child_weight: 0.16983181528269106, n_estimators: 216, reg_alpha: 1.390273909440899, reg_lambda: 0.6519317236818201, scale_pos_weight: 8.758423316352669, subsample: 0.7861149134412877\n",
      "Configuration 2 (0.4000 test score, from iteration 3): colsample_bylevel: 0.7363445107260822, colsample_bytree: 0.8699832795234771, gamma: 0.7180169429023256, learning_rate: 0.019287036299077756, max_depth: 8, min_child_weight: 0.05286384798758806, n_estimators: 296, reg_alpha: 0.11448675248040391, reg_lambda: 0.00022246921506094782, scale_pos_weight: 5.810845849478305, subsample: 0.6181571251630464\n",
      "Configuration 3 (0.2800 test score, from iteration 6): colsample_bylevel: 0.8470776887229806, colsample_bytree: 0.7722586945073454, gamma: 0.8918958902578227, learning_rate: 0.02230891094147749, max_depth: 8, min_child_weight: 0.1813333288867241, n_estimators: 441, reg_alpha: 0.020209055431913876, reg_lambda: 1.022246675041981e-05, scale_pos_weight: 9.708989785261547, subsample: 0.7788791713893122\n",
      "Configuration 4 (0.2667 test score, from iteration 1): colsample_bylevel: 0.642684065287499, colsample_bytree: 0.8705675049493155, gamma: 0.6931755622735222, learning_rate: 0.030537009006022242, max_depth: 4, min_child_weight: 7.330431356819354, n_estimators: 162, reg_alpha: 0.00023800754162119547, reg_lambda: 0.1790501261127564, scale_pos_weight: 8.142995187170802, subsample: 0.8657589328408908\n",
      "Configuration 5 (0.2500 test score, from iteration 2): colsample_bylevel: 0.7472497691056, colsample_bytree: 0.5826055734351328, gamma: 8.191890212413906, learning_rate: 0.02968424379524942, max_depth: 10, min_child_weight: 0.42943316025406436, n_estimators: 769, reg_alpha: 0.4167157305138968, reg_lambda: 73.52141841201113, scale_pos_weight: 9.802707075709598, subsample: 0.7912635879477168\n",
      "\n",
      "The best score from the last run was 0.27999999999999997, while the best score ever achieved in all previous runs is 0.6\n",
      "\n",
      "Remember, tunable hyperparameters are: n_estimators, max_depth, min_child_samples, gamma, scale_pos_weight, learning_rate, subsample, colsample_bylevel, colsample_bytree, reg_alpha, and reg_lambda.\n",
      "\n",
      "Given the insights from the search history, your expertise in ML, and the need to further explore the search space, please suggest refinements for the search space in the next optimization round. Consider both narrowing and expanding the search space for hyperparameters where appropriate.\n",
      "\n",
      "For each recommendation, please:\n",
      "1. Explicitly tie back to any general best practices or patterns you are aware of regarding XGBoost tuning\n",
      "2. Then, relate to the insights from the search history and explain how they align or deviate from these practices or patterns.\n",
      "3. If suggesting an expansion of the search space, please provide a rationale for why a broader range could be beneficial.\n",
      "\n",
      "\n",
      "Briefly summarize your reasoning for the refinements and then present the adjusted configurations. Enclose your refined configurations between python code fences, and assign your configuration to a variable named search_space.\n",
      "\n",
      "\n",
      "\n",
      "Refined Search Space Reasoning:\n",
      "1. Best practices: In XGBoost tuning—especially for imbalanced and PPV-focused problems—it is critical to search for local optima but also periodically re-explore the broader space if local optima degrade or if past strong configs are not rediscovered. Over-narrowing after a single high run can lead to missed global optima or overfit to stochasticity in the validation set.\n",
      "2. Search history evaluation: After the 0.6 run (iteration 5), local-exploitation-based narrowing was recommended and implemented, but all recent configs (iteration 6) dropped back to ~0.28—the same region and space as many earlier, lower-scoring runs. The best 0.6 configuration (from iteration 5) had reg_alpha and reg_lambda much higher than most subsequent search windows allowed—and notably, its gamma was not at the tight cluster edge but mid-range. Scales of colsample/subsample in that run were also a little broader than the more recent, narrowed focus.\n",
      "Thus, not only has the narrow search failed to recover a good config, but it may have overconstrained the local search area or neglected hyperparameter interactions that worked in the best historical config. In such case, best practice is to rebroaden around what worked best and slightly likely success regions.\n",
      "3. Recommendations:\n",
      "- Re-widen n_estimators to (150, 850) and max_depth (7, 12), as test scores and best-ever configs cover these ranges and boundary configs are sometimes top.\n",
      "- learning_rate to (0.011, 0.035) but allow up to 0.05 for possible serendipity at the upper range.\n",
      "- min_child_weight to (0.05, 0.5), as very low values can quickly overfit, but best-ever did have up to ~0.17.\n",
      "- gamma: allow wider (0.1, 2.0) uniformly (captures both prior high and best-ever ~0.3–1.1 values; best-ever benefited from moderate gamma).\n",
      "- reg_alpha/reg_lambda: extend upper to 2 (best-ever used high reg_alpha ~1.3, so allow that region again, loguniform to search low as well).\n",
      "- scale_pos_weight: uniform(8, 5) for 8–13, based on prior top scores, but also allow slightly more for balancing if higher works.\n",
      "- subsample/colsample*: (0.75, 0.22), as most high-performers sit 0.75–0.90 but 0.68–0.87 also helped previously.\n",
      "\n",
      "Summary: Widen search out to re-include the best-ever region, avoid overfocusing on last round’s cluster, and allow a broader range for regularization. If another 0.6 or higher config is not found, still try more global sweeps or re-exam requeued data splits in next rounds.\n",
      "\n",
      "\n",
      "--- Iteration 7/10 ---\n",
      "Top Config Summary:\n",
      "Configuration 1 (0.3000 test score): colsample_bylevel: 0.8273704806938873, colsample_bytree: 0.7652991117494085, gamma: 0.7555131155248872, learning_rate: 0.011310032296106144, max_depth: 9, min_child_weight: 0.21577726106591363, n_estimators: 336, reg_alpha: 2.1512444663590898e-05, reg_lambda: 0.305984908591882, scale_pos_weight: 9.07326944052259, subsample: 0.7978736103783203\n",
      "Configuration 2 (0.3000 test score): colsample_bylevel: 0.7571980952067376, colsample_bytree: 0.8706119026396513, gamma: 1.5275742729277735, learning_rate: 0.029765571661026367, max_depth: 10, min_child_weight: 0.08299428249886603, n_estimators: 212, reg_alpha: 0.08476679368529948, reg_lambda: 0.01303928197628746, scale_pos_weight: 8.320976511545998, subsample: 0.908650628784412\n",
      "Configuration 3 (0.3000 test score): colsample_bylevel: 0.7816784691450883, colsample_bytree: 0.8623570796455284, gamma: 0.11810183573851762, learning_rate: 0.039954985013792285, max_depth: 11, min_child_weight: 0.059152409909846056, n_estimators: 783, reg_alpha: 0.12162737236458733, reg_lambda: 0.11499792325815775, scale_pos_weight: 12.16299749865843, subsample: 0.9159408606543705\n",
      "Configuration 4 (0.3000 test score): colsample_bylevel: 0.7801498254031186, colsample_bytree: 0.837600647249412, gamma: 0.39686023103605816, learning_rate: 0.014100588210898225, max_depth: 12, min_child_weight: 0.17787282377558533, n_estimators: 819, reg_alpha: 0.000584650667794828, reg_lambda: 0.004233381868421212, scale_pos_weight: 11.598974674060466, subsample: 0.8724450330530773\n",
      "Configuration 5 (0.2667 test score): colsample_bylevel: 0.772136787739888, colsample_bytree: 0.7693345007218845, gamma: 1.1328866514898928, learning_rate: 0.017936822284460766, max_depth: 12, min_child_weight: 0.08501105265131878, n_estimators: 697, reg_alpha: 0.11992574350141413, reg_lambda: 1.590098209542121e-05, scale_pos_weight: 9.344582729790591, subsample: 0.920544551047751\n",
      "\n",
      "Last Run Best Score: 0.3\n",
      "No improvement. Consecutive runs without improvement: 2\n",
      "\n",
      "Current top 5 configurations:\n",
      "  1. Score: 0.6000 (Iteration 5)\n",
      "  2. Score: 0.4000 (Iteration 3)\n",
      "  3. Score: 0.3000 (Iteration 7)\n",
      "  4. Score: 0.2800 (Iteration 6)\n",
      "  5. Score: 0.2667 (Iteration 1)\n",
      "Refine Search Space Prompt:\n",
      "\n",
      "Given your previously suggested search space, the obtained top configurations from the last run with their test scores:\n",
      "Configuration 1 (0.3000 test score): colsample_bylevel: 0.8273704806938873, colsample_bytree: 0.7652991117494085, gamma: 0.7555131155248872, learning_rate: 0.011310032296106144, max_depth: 9, min_child_weight: 0.21577726106591363, n_estimators: 336, reg_alpha: 2.1512444663590898e-05, reg_lambda: 0.305984908591882, scale_pos_weight: 9.07326944052259, subsample: 0.7978736103783203\n",
      "Configuration 2 (0.3000 test score): colsample_bylevel: 0.7571980952067376, colsample_bytree: 0.8706119026396513, gamma: 1.5275742729277735, learning_rate: 0.029765571661026367, max_depth: 10, min_child_weight: 0.08299428249886603, n_estimators: 212, reg_alpha: 0.08476679368529948, reg_lambda: 0.01303928197628746, scale_pos_weight: 8.320976511545998, subsample: 0.908650628784412\n",
      "Configuration 3 (0.3000 test score): colsample_bylevel: 0.7816784691450883, colsample_bytree: 0.8623570796455284, gamma: 0.11810183573851762, learning_rate: 0.039954985013792285, max_depth: 11, min_child_weight: 0.059152409909846056, n_estimators: 783, reg_alpha: 0.12162737236458733, reg_lambda: 0.11499792325815775, scale_pos_weight: 12.16299749865843, subsample: 0.9159408606543705\n",
      "Configuration 4 (0.3000 test score): colsample_bylevel: 0.7801498254031186, colsample_bytree: 0.837600647249412, gamma: 0.39686023103605816, learning_rate: 0.014100588210898225, max_depth: 12, min_child_weight: 0.17787282377558533, n_estimators: 819, reg_alpha: 0.000584650667794828, reg_lambda: 0.004233381868421212, scale_pos_weight: 11.598974674060466, subsample: 0.8724450330530773\n",
      "Configuration 5 (0.2667 test score): colsample_bylevel: 0.772136787739888, colsample_bytree: 0.7693345007218845, gamma: 1.1328866514898928, learning_rate: 0.017936822284460766, max_depth: 12, min_child_weight: 0.08501105265131878, n_estimators: 697, reg_alpha: 0.11992574350141413, reg_lambda: 1.590098209542121e-05, scale_pos_weight: 9.344582729790591, subsample: 0.920544551047751\n",
      "\n",
      "Top configurations across ALL runs so far:\n",
      "Configuration 1 (0.6000 test score, from iteration 5): colsample_bylevel: 0.6819796804585989, colsample_bytree: 0.8769995435403075, gamma: 0.36267123343479407, learning_rate: 0.011181214516269689, max_depth: 9, min_child_weight: 0.16983181528269106, n_estimators: 216, reg_alpha: 1.390273909440899, reg_lambda: 0.6519317236818201, scale_pos_weight: 8.758423316352669, subsample: 0.7861149134412877\n",
      "Configuration 2 (0.4000 test score, from iteration 3): colsample_bylevel: 0.7363445107260822, colsample_bytree: 0.8699832795234771, gamma: 0.7180169429023256, learning_rate: 0.019287036299077756, max_depth: 8, min_child_weight: 0.05286384798758806, n_estimators: 296, reg_alpha: 0.11448675248040391, reg_lambda: 0.00022246921506094782, scale_pos_weight: 5.810845849478305, subsample: 0.6181571251630464\n",
      "Configuration 3 (0.3000 test score, from iteration 7): colsample_bylevel: 0.9312735513676957, colsample_bytree: 0.8057029958870318, gamma: 1.180884880527898, learning_rate: 0.04053743988167569, max_depth: 8, min_child_weight: 0.05126491357810808, n_estimators: 303, reg_alpha: 3.118152151528129e-05, reg_lambda: 1.6940313372941593e-05, scale_pos_weight: 8.208196261940783, subsample: 0.9355815248312076\n",
      "Configuration 4 (0.2800 test score, from iteration 6): colsample_bylevel: 0.8470776887229806, colsample_bytree: 0.7722586945073454, gamma: 0.8918958902578227, learning_rate: 0.02230891094147749, max_depth: 8, min_child_weight: 0.1813333288867241, n_estimators: 441, reg_alpha: 0.020209055431913876, reg_lambda: 1.022246675041981e-05, scale_pos_weight: 9.708989785261547, subsample: 0.7788791713893122\n",
      "Configuration 5 (0.2667 test score, from iteration 1): colsample_bylevel: 0.642684065287499, colsample_bytree: 0.8705675049493155, gamma: 0.6931755622735222, learning_rate: 0.030537009006022242, max_depth: 4, min_child_weight: 7.330431356819354, n_estimators: 162, reg_alpha: 0.00023800754162119547, reg_lambda: 0.1790501261127564, scale_pos_weight: 8.142995187170802, subsample: 0.8657589328408908\n",
      "\n",
      "The best score from the last run was 0.3, while the best score ever achieved in all previous runs is 0.6\n",
      "\n",
      "Remember, tunable hyperparameters are: n_estimators, max_depth, min_child_samples, gamma, scale_pos_weight, learning_rate, subsample, colsample_bylevel, colsample_bytree, reg_alpha, and reg_lambda.\n",
      "\n",
      "Given the insights from the search history, your expertise in ML, and the need to further explore the search space, please suggest refinements for the search space in the next optimization round. Consider both narrowing and expanding the search space for hyperparameters where appropriate.\n",
      "\n",
      "For each recommendation, please:\n",
      "1. Explicitly tie back to any general best practices or patterns you are aware of regarding XGBoost tuning\n",
      "2. Then, relate to the insights from the search history and explain how they align or deviate from these practices or patterns.\n",
      "3. If suggesting an expansion of the search space, please provide a rationale for why a broader range could be beneficial.\n",
      "\n",
      "\n",
      "Briefly summarize your reasoning for the refinements and then present the adjusted configurations. Enclose your refined configurations between python code fences, and assign your configuration to a variable named search_space.\n",
      "\n",
      "\n",
      "\n",
      "Refined Search Space Reasoning:\n",
      "1. Best Practices: If previously-identified high-performing regions (such as the 0.6 config) aren't being rediscovered or improved via local exploitation, best practice is to alternate focused search with periodic global re-broadening or multimodal search. PPV optimization for highly imbalanced, tabular XGBoost models particularly rewards periodic re-widening, testing more regularization, and exploring possible interactions between learning-rate, regularization, min_child_weight/gamma, and sampling—which may not be captured by local search alone.\n",
      "\n",
      "2. Search History Relation: Since the 0.6 score, successive rounds of both narrow and moderate search have plateaued at 0.3. Notably, the 0.6 config used high reg_alpha and reg_lambda, and slightly lower learning_rate than most recent configs, as well as mid-to-lower colsample/subsample versus the cluster of recent configs at the high end. No best recent configs have used more than 12 for scale_pos_weight. All high-performing configs (~0.3) now come from a relatively similar band, suggesting possible overexploitation with insufficient random exploration or multimodal search.\n",
      "\n",
      "3. Recommendations:\n",
      "- Reintroduce higher regularization: reg_alpha/reg_lambda up to 3, as in the 0.6 best-ever; keep loguniform, but span 1e-5 to 3.\n",
      "- Expand n_estimators (150, 900) and max_depth (7, 13) to avoid boundary effects stopping optimal trees.\n",
      "- Allow learning_rate lower bound to 0.007, upper to 0.04, to check slower and slightly higher learning.\n",
      "- Broaden min_child_weight to (0.03, 0.6), to accommodate both very low and modest regularization.\n",
      "- Expand gamma to (0.05, 2.2), as best came from 0.36–1.7, but keep range for possible pruned or rich trees.\n",
      "- Scale_pos_weight: widen to (7, 7), covering 7–14, as true class ratio is ~14, and test for higher balancing.\n",
      "- colsample_bytree/colsample_bylevel/subsample: (0.68, 0.3), spanning both lower and upper end values found historically good.\n",
      "\n",
      "This returns exploration to both underused spaces (esp. regularization and scale_pos_weight), and previously high-PPV configs. If no improvement, the plateau may be dataset driven or require feature engineering/data augmentation.\n",
      "\n",
      "Summary: Oscillate back to re-broaden the search area. This ensures optimization doesn't get stuck in narrow, unproductive local basins and can potentially result in recovering or surpassing best-ever configs.\n",
      "\n",
      "--- Iteration 8/10 ---\n",
      "Top Config Summary:\n",
      "Configuration 1 (0.4500 test score): colsample_bylevel: 0.9274674824699732, colsample_bytree: 0.7295677538876029, gamma: 1.6214516473846665, learning_rate: 0.021500329377692712, max_depth: 13, min_child_weight: 0.12772681250971066, n_estimators: 816, reg_alpha: 1.2657762334325895, reg_lambda: 3.453936658020174e-05, scale_pos_weight: 7.925570321409866, subsample: 0.7231357310510297\n",
      "Configuration 2 (0.4000 test score): colsample_bylevel: 0.8081220904787014, colsample_bytree: 0.7048717834267818, gamma: 1.0859310706653673, learning_rate: 0.01191590380798365, max_depth: 10, min_child_weight: 0.3267439793017977, n_estimators: 208, reg_alpha: 0.0006572931544856299, reg_lambda: 0.0025200408788246405, scale_pos_weight: 7.444563617317744, subsample: 0.832138990975363\n",
      "Configuration 3 (0.4000 test score): colsample_bylevel: 0.9726900321264366, colsample_bytree: 0.9129741225047899, gamma: 0.6162877911614237, learning_rate: 0.03233506072295373, max_depth: 11, min_child_weight: 0.10647241092646943, n_estimators: 507, reg_alpha: 0.023889395610984927, reg_lambda: 0.003803916549946706, scale_pos_weight: 7.55906013283202, subsample: 0.9014871004378113\n",
      "Configuration 4 (0.4000 test score): colsample_bylevel: 0.6844068885385972, colsample_bytree: 0.8207448500390526, gamma: 0.4701239184892846, learning_rate: 0.013073031356790877, max_depth: 9, min_child_weight: 0.17368755039061212, n_estimators: 294, reg_alpha: 0.4252250096228019, reg_lambda: 9.909362547364222e-05, scale_pos_weight: 11.784737108470669, subsample: 0.951925231275482\n",
      "Configuration 5 (0.4000 test score): colsample_bylevel: 0.8208597955230544, colsample_bytree: 0.8608790835690094, gamma: 0.3581640412003727, learning_rate: 0.012762970213058746, max_depth: 7, min_child_weight: 0.0475775620731125, n_estimators: 273, reg_alpha: 0.28997295151148395, reg_lambda: 0.4111676363981249, scale_pos_weight: 7.806984908545676, subsample: 0.8128531774923323\n",
      "\n",
      "Last Run Best Score: 0.45\n",
      "No improvement. Consecutive runs without improvement: 3\n",
      "\n",
      "Current top 5 configurations:\n",
      "  1. Score: 0.6000 (Iteration 5)\n",
      "  2. Score: 0.4500 (Iteration 8)\n",
      "  3. Score: 0.4000 (Iteration 3)\n",
      "  4. Score: 0.3000 (Iteration 7)\n",
      "  5. Score: 0.2800 (Iteration 6)\n",
      "Early stopping: No improvement for 3 consecutive runs\n",
      "\n",
      "Tuning completed after 8 iterations\n",
      "Best score achieved: 0.6\n",
      "Top 5 configurations found:\n",
      "  1. Score: 0.6000 (Iteration 5)\n",
      "  2. Score: 0.4500 (Iteration 8)\n",
      "  3. Score: 0.4000 (Iteration 3)\n",
      "  4. Score: 0.3000 (Iteration 7)\n",
      "  5. Score: 0.2800 (Iteration 6)\n",
      "Score progression: [np.float64(0.26666666666666666), np.float64(0.25), np.float64(0.4), np.float64(0.21666666666666665), np.float64(0.6), np.float64(0.27999999999999997), np.float64(0.3), np.float64(0.45)]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "llm_tuner.tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'colsample_bylevel': np.float64(0.6819796804585989), 'colsample_bytree': np.float64(0.8769995435403075), 'gamma': np.float64(0.36267123343479407), 'learning_rate': np.float64(0.011181214516269689), 'max_depth': 9, 'min_child_weight': np.float64(0.16983181528269106), 'n_estimators': 216, 'reg_alpha': np.float64(1.390273909440899), 'reg_lambda': np.float64(0.6519317236818201), 'scale_pos_weight': np.float64(8.758423316352669), 'subsample': np.float64(0.7861149134412877)}\n",
      "Best score: 0.6\n",
      "Best config: {'colsample_bylevel': np.float64(0.6819796804585989), 'colsample_bytree': np.float64(0.8769995435403075), 'gamma': np.float64(0.36267123343479407), 'learning_rate': np.float64(0.011181214516269689), 'max_depth': 9, 'min_child_weight': np.float64(0.16983181528269106), 'n_estimators': 216, 'reg_alpha': np.float64(1.390273909440899), 'reg_lambda': np.float64(0.6519317236818201), 'scale_pos_weight': np.float64(8.758423316352669), 'subsample': np.float64(0.7861149134412877)}\n",
      "Completed 8 iterations\n",
      "Score improvement: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Get just the best configuration\n",
    "best_config = llm_tuner.get_best_config()\n",
    "print(\"Best hyperparameters:\", best_config)\n",
    "\n",
    "# Get comprehensive summary\n",
    "summary = llm_tuner.get_tuning_summary()\n",
    "print(f\"Best score: {summary['best_score']}\")\n",
    "print(f\"Best config: {summary['best_config']}\")\n",
    "print(f\"Completed {summary['total_iterations']} iterations\")\n",
    "print(f\"Score improvement: {summary['improvement_over_baseline']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = X_transformed.drop('claim_status', axis=1)\n",
    "y_df = X_transformed['claim_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_config:\n",
    "    final_model = XGBClassifier(**best_config)\n",
    "    final_model.fit(x_df, y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = fe.transform(X_test)\n",
    "X_test_transformed[categorical_cols] = encoder.transform(X_test_transformed[categorical_cols])\n",
    "\n",
    "y_pred = final_model.predict(X_test_transformed)\n",
    "y_pred_proba = final_model.predict_proba(X_test_transformed)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef\n",
    ")\n",
    "\n",
    "\n",
    "def metrics_display(y_test, y_pred, y_pred_proba):\n",
    "    \n",
    "    # Obtain confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "   \n",
    "    # Output classification metrics\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "   \n",
    "    print(f'ROC_AUC score: {roc_auc_score(y_test, y_pred_proba):.3f}')\n",
    "    print(f'f1 score: {f1_score(y_test, y_pred):.3f}')\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%')\n",
    "    print(f'Precision: {precision_score(y_test, y_pred)*100:.2f}%')\n",
    "    print(f'Detection rate: {recall_score(y_test, y_pred)*100:.2f}%')\n",
    "    print(f'False alarm rate: {fp / (tn+fp)*100}%')\n",
    "    print(f'MCC: {matthews_corrcoef(y_test, y_pred):.2f}')\n",
    "   \n",
    "    # Display confusion matrix\n",
    "    # ConfusionMatrixDisplay.from_predictions(y_test, y_pred, values_format='.5g', colorbar=False)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC score: 0.621\n",
      "f1 score: 0.096\n",
      "Accuracy: 88.25%\n",
      "Precision: 9.62%\n",
      "Detection rate: 9.62%\n",
      "False alarm rate: 6.283422459893048%\n",
      "MCC: 0.03\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_display(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
